-- 插入产品表
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (1, 'DE', '数据开发、任务运维、作业调度、数据监控', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (2, 'QE', '数据查询、分析', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (3, 'LC', '元数据管理、数据管理、数据治理', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (4, 'General', '权限、工单、个人中心', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (5, '其他', '其他', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (6, 'DQC', 'DQC', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_product(id, name, description, delete_status, create_by, update_by) VALUES (7, 'BI', 'dashboard', '0', 'admin', 'admin');

-- 插入角色表
INSERT INTO ds_task_${tenantName}.access_role (id, name, description, delete_status, CREATE_BY, UPDATE_BY) VALUES (1, 'admin', 'admin', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.access_role (id, name, description, delete_status, CREATE_BY, UPDATE_BY) VALUES (5, 'common', 'common', '0', 'admin', 'admin');

-- 插入菜单信息
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (10, 'access_manager', '权限管理', '1', -1, '权限管理', '/jurisdiction', '0', 'admin', '2022-04-15 17:44:00', 'admin', '2022-05-06 07:27:33', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (19, 'user_manager', '用户', '2', 10, 'ds用户管理', '/jurisdiction/user', '0', 'admin', '2022-04-15 18:03:00', 'admin', '2023-05-23 12:23:40', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (25, 'role_manager', '账号类型', '2', 10, '角色管理', '/jurisdiction/role', '0', 'admin', '2022-04-15 18:16:00', 'admin', '2023-05-23 12:23:44', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (1579, 'task-manager', '任务管理', '1', -1, '任务管理', '/task', '0', 'licg', '2022-04-15 23:46:00', 'licg', '2022-04-15 23:46:00', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (1582, 'config-manager', '配置管理', '1', -1, '配置管理', '/config', '0', 'licg', '2022-04-15 23:52:00', 'licg', '2022-04-15 23:52:00', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (1583, 'task_list', '任务列表', '2', 1579, '任务列表', '/task/list', '0', 'admin', '2022-04-15 23:54:00', 'admin', '2022-04-15 23:54:00', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (1863, 'admin-manager', '管理员管理', '1', -1, '管理员管理', '/admin', '0', 'admin', '2022-04-16 00:58:00', 'admin', '2022-04-16 00:58:00', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2095, 'data-analysis', '数据分析', '1', -1, '数据分析', '/data-analysis', '0', 'admin', '2022-04-16 01:23:00', 'admin', '2022-04-16 01:23:00', '0', 2);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2096, 'data-query', 'SQL查询', '2', 2095, '数据查询', '/data-analysis/query', '0', 'admin', '2022-04-16 01:25:00', 'admin', '2023-05-23 12:24:15', '0', 2);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2129, 'order_list', '工单列表', '2', 1863, '工单列表', '/admin/order/list', '0', 'admin', '2022-04-16 01:42:00', 'admin', '2022-04-16 01:42:00', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2268, 'workflow', '工作流管理', '2', 1579, '工作流管理', '/task/workflow', '0', 'admin', '2022-07-07 03:09:01', 'admin', '2022-07-11 03:15:57', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2312, 'sourceInstance', '数据源实例', '2', 1582, '数据源实例', '/config/sourceInstance', '0', 'admin', '2022-08-26 04:02:05', 'admin', '2022-08-26 04:02:05', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2355, 'home-mana', '首页管理', '2', 2372, '首页管理', '/home', '0', 'admin', '2022-09-09 10:09:24', 'admin', '2022-10-10 05:19:57', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2372, 'dashboard', '概览页', '1', -1, '概览页', '/', '0', 'admin', '2022-09-23 08:24:40', 'admin', '2022-09-23 08:24:40', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2444, 'meta', '元数据', '1', -1, '元数据', '/meta', '0', 'admin', '2022-12-19 05:51:50', 'admin', '2022-12-19 05:51:50', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2445, 'meta-list', '元数据列表', '2', 2444, '元数据列表', '/meta/list', '0', 'admin', '2022-12-19 05:59:23', 'admin', '2022-12-19 05:59:23', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2446, 'meta-detail', '元数据详情', '2', 2444, '元数据详情', '/meta/detail', '0', 'admin', '2022-12-19 06:00:01', 'admin', '2022-12-19 06:00:01', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2478, 'artifact', '文件管理', '2', 1579, '文件管理', '/task/artifact', '0', 'admin', '2023-05-10 12:17:56', 'admin', '2023-05-10 12:17:56', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (110000, 'admin_manager', '管理员管理', '2', 10, '管理员管理', '/admin/manager', '0', 'admin', '2023-06-09 02:51:36', 'admin', '2023-06-09 02:51:36', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (110001, 'super_admin_manager', '超级管理员管理', '2', 10, '超级管理员管理', '/superadmin/manager', '0', 'admin', '2023-06-09 02:51:37', 'admin', '2023-06-09 02:51:37', '0', 4);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (2477, 'announcement', '公告', '2', 1863, '公告', '/admin/announcement', '0', 'admin', '2023-05-10 12:01:47', 'admin', '2023-05-10 12:01:47', '0', 1);
INSERT INTO ds_task_${tenantName}.access_menu(id, code, name, `level`, parent_menu_id, description, url, delete_status, CREATE_BY, CREATE_TIME, UPDATE_BY, UPDATE_TIME, valid, product_id) VALUES (110002, 'teamowner', '用户组管理员', '2', 10, '用户组管理员', '/teamowner/manager', '0', 'admin', '2023-06-09 02:51:37', 'admin', '2023-06-09 02:51:37', '0', 4);



INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'10','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'19','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'25','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'1579','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'1582','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'1583','admin','admin');

INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'1863','admin','admin');

INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2095','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2096','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2129','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2268','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2312','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2355','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2372','admin','admin');


INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2444','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2445','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2446','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2478','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'110000','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'110001','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (1,'2477','admin','admin');


INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'10','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'1579','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'1583','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'1582','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2312','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'1863','admin','admin');

INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2129','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2095','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2096','admin','admin');

INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2444','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2445','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2268','admin','admin');
INSERT INTO ds_task_${tenantName}.access_role_menu (role_id,menu_id,CREATE_BY,UPDATE_BY) VALUES (5,'2478','admin','admin');


-- 初始化连接器定义表
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (7, 'BigQuery', 'airbyte/source-bigquery', '0.1.7', 'https://docs.airbyte.io/integrations/sources/bigquery', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/bigquery.svg', 'source', 'database', '{"supportsDBT": true, "documentationUrl": "https://docs.airbyte.io/integrations/sources/bigquery", "supportsIncremental": true, "supported_sync_modes": ["overwrite", "append", "append_dedup"], "supportsNormalization": true, "connectionSpecification": {"type": "object", "title": "BigQuery Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["project_id", "credentials_json"], "properties": {"dataset_id": {"type": "string", "title": "Default Dataset ID", "description": "The dataset ID to search for tables and views. If you are only loading data from one dataset, setting this option could result in much faster schema discovery."}, "project_id": {"type": "string", "title": "Project ID", "description": "The GCP project ID for the project containing the target BigQuery dataset."}, "credentials_json": {"type": "string", "title": "Credentials JSON", "description": "The contents of your Service Account Key JSON file. See the <a href=\\"https://docs.airbyte.io/integrations/sources/bigquery#setup-the-bigquery-source-in-airbyte\\">docs</a> for more information on how to obtain this key.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (8, 'Short.io', 'airbyte/source-shortio', '0.1.2', 'https://docs.airbyte.io/integrations/sources/shortio', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/short.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://developers.short.io/reference", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Shortio Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["domain_id", "secret_key", "start_date"], "properties": {"domain_id": {"type": "string", "title": "Domain ID", "desciprtion": "Short.io Domain ID", "airbyte_secret": false}, "secret_key": {"type": "string", "title": "Secret Key", "description": "Short.io Secret Key", "airbyte_secret": true}, "start_date": {"type": "string", "title": "Start Date", "description": "UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated.", "airbyte_secret": false}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (9, 'Confluence', 'airbyte/source-confluence', '0.1.1', 'https://docs.airbyte.io/integrations/sources/confluence', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/confluence.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Confluence Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_token", "domain_name", "email"], "properties": {"email": {"type": "string", "examples": ["abc@example.com"], "description": "Your Confluence login email"}, "api_token": {"type": "string", "description": "Please follow the Jira confluence for generating an API token: https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/", "airbyte_secret": true}, "domain_name": {"type": "string", "examples": ["example.atlassian.net"], "description": "Your Confluence domain name"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (14, 'Twilio', 'airbyte/source-twilio', '0.1.4', 'https://docs.airbyte.io/integrations/sources/twilio', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/twilio.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/twilio", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Twilio Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["account_sid", "auth_token", "start_date"], "properties": {"auth_token": {"type": "string", "title": "Auth Token", "description": "Twilio Auth Token.", "airbyte_secret": true}, "start_date": {"type": "string", "title": "Replication Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2020-10-01T00:00:00Z"], "description": "UTC date and time in the format 2020-10-01T00:00:00Z. Any data before this date will not be replicated."}, "account_sid": {"type": "string", "title": "Account ID", "description": "Twilio account SID", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (15, 'Commercetools', 'airbyte/source-commercetools', '0.1.0', 'https://docs.airbyte.io/integrations/sources/commercetools', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/commercetools.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/commercetools", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Commercetools Source CDK Specifications", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["region", "start_date", "host", "project_key", "client_id", "client_secret"], "properties": {"host": {"enum": ["gcp", "aws"], "type": "string", "description": "The cloud provider your shop is hosted. See: https://docs.commercetools.com/api/authorization"}, "region": {"type": "string", "examples": ["us-central1", "australia-southeast1"], "description": "The region of the platform."}, "client_id": {"type": "string", "description": "Id of API Client.", "airbyte_secret": true}, "start_date": {"type": "string", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-01-01"], "description": "The date you would like to replicate data. Format: YYYY-MM-DD."}, "project_key": {"type": "string", "description": "The project key"}, "client_secret": {"type": "string", "description": "The password of secret of API Client.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (16, 'MySQL', 'airbyte/source-mysql', '0.5.11', 'https://docs.airbyte.io/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mysql.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/mysql", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "MySql Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username", "replication_method"], "properties": {"ssl": {"type": "boolean", "order": 6, "title": "SSL Connection", "default": false, "description": "Encrypt data using SSL."}, "host": {"type": "string", "order": 0, "title": "Host", "description": "The host name of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 3306, "maximum": 65536, "minimum": 0, "examples": ["3306"], "description": "The port to connect to."}, "database": {"type": "string", "order": 2, "title": "Database", "description": "The database name."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "The password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "title": "Username", "description": "The username which is used to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}, "jdbc_url_params": {"type": "string", "order": 5, "default":"useSSL=false","title": "JDBC URL Params", "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3)."}, "replication_method": {"enum": ["STANDARD", "CDC"], "type": "string", "order": 7, "title": "Replication Method", "default": "STANDARD", "description": "Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 1, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (21, 'IBM Db2', 'airbyte/source-db2', '0.1.10', 'https://docs.airbyte.io/integrations/sources/db2', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/db2.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/db2", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "IBM Db2 Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "db", "username", "password", "encryption"], "properties": {"db": {"type": "string", "order": 2, "examples": ["default"], "description": "Name of the database."}, "host": {"type": "string", "order": 0, "description": "Host of the Db2."}, "port": {"type": "integer", "order": 1, "default": 8123, "maximum": 65536, "minimum": 0, "examples": ["8123"], "description": "Port of the database."}, "password": {"type": "string", "order": 4, "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "description": "Username to use to access the database."}, "encryption": {"type": "object", "oneOf": [{"title": "Unencrypted", "required": ["encryption_method"], "properties": {"encryption_method": {"enum": ["unencrypted"], "type": "string", "const": "unencrypted", "default": "unencrypted"}}, "description": "Data transfer will not be encrypted.", "additionalProperties": false}, {"title": "TLS Encrypted (verify certificate)", "required": ["encryption_method", "ssl_certificate"], "properties": {"ssl_certificate": {"type": "string", "title": "SSL PEM file", "multiline": true, "description": "Privacy Enhanced Mail (PEM) files are concatenated certificate containers frequently used in certificate installations", "airbyte_secret": true}, "encryption_method": {"enum": ["encrypted_verify_certificate"], "type": "string", "const": "encrypted_verify_certificate", "default": "encrypted_verify_certificate"}, "key_store_password": {"type": "string", "title": "Key Store Password. This field is optional. If you do not fill in this field, the password will be randomly generated.", "description": "Key Store Password", "airbyte_secret": true}}, "description": "Verify and use the cert provided by the server.", "additionalProperties": false}], "order": 5, "title": "Encryption", "description": "Encryption method to use when communicating with the database"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (23, 'Facebook Pages', 'airbyte/source-facebook-pages', '0.1.6', 'https://docs.airbyte.com/integrations/sources/facebook-pages', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/facebook.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/facebook-pages", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": [], "oauthFlowInitParameters": [], "oauthFlowOutputParameters": [["access_token"]]}}, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Facebook Pages Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["access_token", "page_id"], "properties": {"page_id": {"type": "string", "title": "Page ID", "description": "Page ID"}, "access_token": {"type": "string", "title": "Page Access Token", "description": "Facebook Page Access Token", "airbyte_secret": true}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (26, 'Snowflake', 'airbyte/source-snowflake', '0.1.12', 'https://docs.airbyte.io/integrations/sources/snowflake', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/snowflake.svg', 'source', 'database', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "auth_type"], "auth_flow_type": "oauth2.0", "predicate_value": "OAuth", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"access_token": {"type": "string", "path_in_connector_config": ["credentials", "access_token"]}, "refresh_token": {"type": "string", "path_in_connector_config": ["credentials", "refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"host": {"type": "string", "path_in_connector_config": ["host"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/snowflake", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Snowflake Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "role", "warehouse", "database", "schema"], "properties": {"host": {"type": "string", "order": 1, "title": "Account Name", "examples": ["accountname.us-east-2.aws.snowflakecomputing.com"], "description": "The host domain of the snowflake instance (must include the account, region, cloud environment, and end with snowflakecomputing.com)."}, "role": {"type": "string", "order": 2, "title": "Role", "examples": ["AIRBYTE_ROLE"], "description": "The role you created for Airbyte to access Snowflake."}, "schema": {"type": "string", "order": 5, "title": "Schema", "examples": ["AIRBYTE_SCHEMA"], "description": "The source Snowflake schema tables."}, "database": {"type": "string", "order": 4, "title": "Database", "examples": ["AIRBYTE_DATABASE"], "description": "The database you created for Airbyte to access data."}, "warehouse": {"type": "string", "order": 3, "title": "Warehouse", "examples": ["AIRBYTE_WAREHOUSE"], "description": "The warehouse you created for Airbyte to access data."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "order": 0, "title": "OAuth2.0", "required": ["client_id", "client_secret", "auth_type"], "properties": {"auth_type": {"type": "string", "const": "OAuth", "order": 0, "default": "OAuth"}, "client_id": {"type": "string", "order": 1, "title": "Client ID", "description": "The Client ID of your Snowflake developer application.", "airbyte_secret": true}, "access_token": {"type": "string", "order": 3, "title": "Access Token", "description": "Access Token for making authenticated requests.", "airbyte_secret": true}, "client_secret": {"type": "string", "order": 2, "title": "Client Secret", "description": "The Client Secret of your Snowflake developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "order": 4, "title": "Refresh Token", "description": "Refresh Token for making authenticated requests.", "airbyte_secret": true}}}, {"type": "object", "order": 1, "title": "Username and Password", "required": ["username", "password", "auth_type"], "properties": {"password": {"type": "string", "order": 2, "title": "Password", "description": "The password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 1, "title": "Username", "examples": ["AIRBYTE_USER"], "description": "The username you created to allow Airbyte to access the database."}, "auth_type": {"type": "string", "const": "username/password", "order": 0, "default": "username/password"}}}], "order": 0, "title": "Authorization Method"}, "jdbc_url_params": {"type": "string", "order": 6, "title": "JDBC URL Params", "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3)."}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (31, 'SearchMetrics', 'airbyte/source-search-metrics', '0.1.1', 'https://docs.airbyte.io/integrations/sources/search-metrics', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/test/datasource/852eeccabf6d41efaa13431c8350b75b/萨摩耶.jpeg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/seacrh-metrics", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source Search Metrics Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key", "client_secret", "country_code", "start_date"], "properties": {"api_key": {"type": "string", "title": "API Key", "description": "", "airbyte_secret": true}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}[0-9]{2}[0-9]{2}$", "examples": ["20200925"], "description": "Data generated in SearchMetrics after this date will be replicated. This date must be specified in the format YYYY-MM-DDT00:00:00Z."}, "country_code": {"enum": ["", "AR", "AU", "AT", "BE", "BR", "CA", "CN", "CO", "DK", "FI", "FR", "DE", "HK", "IN", "IE", "IT", "JP", "MX", "NL", "NO", "PL", "RU", "SG", "ZA", "ES", "SE", "CH", "TR", "US", "GB"], "type": "string", "order": 2, "title": "Country Code", "default": "", "description": "The region of the S3 staging bucket to use if utilising a copy strategy."}, "client_secret": {"type": "string", "title": "Client Secret", "description": "", "airbyte_secret": true}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (32, 'BigCommerce', 'airbyte/source-bigcommerce', '0.1.5', 'https://docs.airbyte.io/integrations/sources/bigcommerce', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/bigcommerce.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/bigcommerce", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "BigCommerce Source CDK Specifications", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["start_date", "store_hash", "access_token"], "properties": {"start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-01-01"], "description": "The date you would like to replicate data. Format: YYYY-MM-DD."}, "store_hash": {"type": "string", "title": "Store Hash", "description": "The hash code of the store. For https://api.bigcommerce.com/stores/HASH_CODE/v3/, The store''s hash code is ''HASH_CODE''."}, "access_token": {"type": "string", "title": "Access Token", "description": "Access Token for making authenticated requests.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (37, 'Pulsar', 'airbyte/destination-pulsar', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/pulsar', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/pulsar.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/pulsar", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Pulsar Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["brokers", "use_tls", "topic_type", "topic_tenant", "topic_namespace", "topic_pattern", "compression_type", "send_timeout_ms", "max_pending_messages", "max_pending_messages_across_partitions", "batching_enabled", "batching_max_messages", "batching_max_publish_delay", "block_if_queue_full"], "properties": {"brokers": {"type": "string", "title": "Pulsar brokers", "examples": ["broker1:6650,broker2:6650"], "description": "A list of host/port pairs to use for establishing the initial connection to the Pulsar cluster."}, "use_tls": {"type": "boolean", "title": "Use TLS", "default": false, "description": "Whether to use TLS encryption on the connection."}, "topic_test": {"type": "string", "title": "Test topic", "examples": ["test.topic"], "description": "Topic to test if Airbyte can produce messages."}, "topic_type": {"enum": ["persistent", "non-persistent"], "type": "string", "title": "Topic type", "default": "persistent", "description": "It identifies type of topic. Pulsar supports two kind of topics: persistent and non-persistent. In persistent topic, all messages are durably persisted on disk (that means on multiple disks unless the broker is standalone), whereas non-persistent topic does not persist message into storage disk."}, "topic_tenant": {"type": "string", "title": "Topic tenant", "default": "public", "examples": ["public"], "description": "The topic tenant within the instance. Tenants are essential to multi-tenancy in Pulsar, and spread across clusters."}, "producer_name": {"type": "string", "title": "Producer name", "examples": ["airbyte-producer"], "description": "Name for the producer. If not filled, the system will generate a globally unique name which can be accessed with."}, "producer_sync": {"type": "boolean", "title": "Sync producer", "default": false, "description": "Wait synchronously until the record has been sent to Pulsar."}, "topic_pattern": {"type": "string", "title": "Topic pattern", "examples": ["sample.topic", "{namespace}.{stream}.sample"], "description": "Topic pattern in which the records will be sent. You can use patterns like ''{namespace}'' and/or ''{stream}'' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention."}, "send_timeout_ms": {"type": "integer", "title": "Message send timeout", "default": 30000, "description": "If a message is not acknowledged by a server before the send-timeout expires, an error occurs (in ms)."}, "topic_namespace": {"type": "string", "title": "Topic namespace", "default": "default", "examples": ["default"], "description": "The administrative unit of the topic, which acts as a grouping mechanism for related topics. Most topic configuration is performed at the namespace level. Each tenant has one or multiple namespaces."}, "batching_enabled": {"type": "boolean", "title": "Enable batching", "default": true, "description": "Control whether automatic batching of messages is enabled for the producer."}, "compression_type": {"enum": ["NONE", "LZ4", "ZLIB", "ZSTD", "SNAPPY"], "type": "string", "title": "Compression type", "default": "NONE", "description": "Compression type for the producer."}, "block_if_queue_full": {"type": "boolean", "title": "Block if queue is full", "default": false, "description": "If the send operation should block when the outgoing message queue is full."}, "max_pending_messages": {"type": "integer", "title": "Max pending messages", "default": 1000, "description": "The maximum size of a queue holding pending messages."}, "batching_max_messages": {"type": "integer", "title": "Batching max messages", "default": 1000, "description": "Maximum number of messages permitted in a batch."}, "batching_max_publish_delay": {"type": "integer", "title": "Batching max publish delay", "default": 1, "description": " Time period in milliseconds within which the messages sent will be batched."}, "max_pending_messages_across_partitions": {"type": "integer", "title": "Max pending messages across partitions", "default": 50000, "description": "The maximum number of pending messages across partitions."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (40, 'Snapchat Marketing', 'airbyte/source-snapchat-marketing', '0.1.4', 'https://docs.airbyte.io/integrations/sources/snapchat-marketing', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/snapchat.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/snapchat-marketing", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": [], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Snapchat Marketing Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["client_id", "client_secret", "refresh_token"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Snapchat developer application.", "airbyte_secret": true}, "start_date": {"type": "string", "title": "Start Date", "default": "1970-01-01", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-01-01"], "description": "UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated."}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Snapchat developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "Refresh Token to renew the expired Access Token.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (43, 'Jenkins', 'farosai/airbyte-jenkins-source', '0.1.23', 'https://docs.airbyte.io/integrations/sources/jenkins', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/jenkins.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.faros.ai", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Jenkins Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["server_url", "user", "token"], "properties": {"user": {"type": "string", "description": "Jenkins User"}, "depth": {"type": "number", "title": "Depth", "description": "Jenkins JSON API does not support deep scan, it is required to generate a suitable tree for the corresponding depth. Job in some cases have many sub jobs, depth needs to quantify how many sub jobs are showed. If depth is not provided we will try to compute it automatically"}, "token": {"type": "string", "title": "Jenkins Token", "airbyte_secret": true}, "pageSize": {"type": "integer", "title": "Page Size", "default": 10, "minimum": 1, "description": "Quantity of jobs on a single page fetched from Jenkins"}, "server_url": {"type": "string", "title": "Jenkins Server URL", "examples": ["https://my-jenkins-server.example.com"]}, "last100Builds": {"type": "boolean", "title": "Last 100 Builds Only", "default": false, "description": "Fetch only 100 last builds from Jenkins server"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (44, 'PagerDuty', 'farosai/airbyte-pagerduty-source', '0.1.23', 'https://docs.airbyte.io/integrations/sources/pagerduty', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/pagerduty.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.faros.ai", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "PagerDuty Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["token"], "properties": {"token": {"type": "string", "title": "PagerDuty API key", "airbyte_secret": true}, "pageSize": {"type": "number", "title": "Page Size", "default": 25, "maximum": 25, "minimum": 1, "description": "page size to use when querying PagerDuty API"}, "cutoffDays": {"type": "number", "title": "Cutoff Days", "default": 90, "minimum": 1, "description": "fetch pipelines updated in the last number of days"}, "defaultSeverity": {"type": "string", "title": "Severity category", "pattern": "^(Sev[0-5])?(Custom)?$", "examples": ["Sev1", "Sev2", "Sev3", "Sev4", "Sev5", "Custom"], "description": "A default severity category if not present"}, "incidentLogEntriesOverview": {"type": "boolean", "title": "Incident Log Entries Overview", "default": true, "description": "If true, will return a subset of log entries that show only the most important changes to the incident."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (47, 'QuickBooks', 'airbyte/source-quickbooks-singer', '0.1.5', 'https://docs.airbyte.io/integrations/sources/quickbooks', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/qb.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.com/integrations/sources/quickbooks", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source QuickBooks Singer Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["client_id", "client_secret", "refresh_token", "realm_id", "user_agent", "start_date", "sandbox"], "properties": {"sandbox": {"type": "boolean", "title": "Sandbox", "default": false, "description": "Determines whether to use the sandbox or production environment."}, "realm_id": {"type": "string", "title": "Realm ID", "description": "Labeled Company ID. The Make API Calls panel is populated with the realm id and the current access token.", "airbyte_secret": true}, "client_id": {"type": "string", "title": "Client ID", "description": "Identifies which app is making the request. Obtain this value from the Keys tab on the app profile via My Apps on the developer site. There are two versions of this key: development and production."}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2021-03-20T00:00:00Z"], "description": "The default value to use if no bookmark exists for an endpoint (rfc3339 date string). E.g, 2021-03-20T00:00:00Z. Any data before this date will not be replicated."}, "user_agent": {"type": "string", "title": "User Agent", "description": "Process and email for API logging purposes. Example: tap-quickbooks <api_user_email@your_company.com>."}, "client_secret": {"type": "string", "title": "Client Secret", "description": " Obtain this value from the Keys tab on the app profile via My Apps on the developer site. There are two versions of this key: development and production.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "A token used when refreshing the access token.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (54, 'Monday', 'airbyte/source-monday', '0.1.3', 'https://docs.airbyte.io/integrations/sources/monday', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/monday.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "auth_type"], "auth_flow_type": "oauth2.0", "predicate_value": "oauth2.0", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"access_token": {"type": "string", "path_in_connector_config": ["credentials", "access_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": true}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"subdomain": {"type": "string", "path_in_connector_config": ["credentials", "subdomain"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/monday", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Monday Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": [], "properties": {"credentials": {"type": "object", "oneOf": [{"type": "object", "title": "OAuth2.0", "required": ["auth_type", "client_id", "client_secret", "access_token"], "properties": {"auth_type": {"enum": ["oauth2.0"], "type": "string", "const": "oauth2.0", "order": 1, "default": "oauth2.0"}, "client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your OAuth application.", "airbyte_secret": true}, "subdomain": {"type": "string", "order": 0, "title": "Subdomain/Slug (Optional)", "default": "", "description": "Slug/subdomain of the account, or the first part of the URL that comes before .monday.com"}, "access_token": {"type": "string", "title": "Access Token", "description": "Access Token for making authenticated requests.", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your OAuth application.", "airbyte_secret": true}}}, {"type": "object", "title": "API Token", "required": ["auth_type", "api_token"], "properties": {"api_token": {"type": "string", "title": "Personal API Token", "description": "API Token for making authenticated requests.", "airbyte_secret": true}, "auth_type": {"enum": ["api_token"], "type": "string", "const": "api_token", "order": 0, "default": "api_token"}}}], "title": "Authorization Method"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (56, 'Customer.io', 'farosai/airbyte-customer-io-source', '0.1.23', 'https://docs.airbyte.io/integrations/sources/customer-io', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/customer-io.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.faros.ai", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Customer.io Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["app_api_key"], "properties": {"app_api_key": {"type": "string", "title": "Customer.io App API Key", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (57, 'Linnworks', 'airbyte/source-linnworks', '0.1.5', 'https://docs.airbyte.io/integrations/sources/linnworks', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/linnworks.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/linnworks", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Linnworks Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["application_id", "application_secret", "token", "start_date"], "properties": {"token": {"type": "string", "title": "API Token"}, "start_date": {"type": "string", "title": "Start Date", "format": "date-time", "description": "UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated."}, "application_id": {"type": "string", "title": "Application ID.", "description": "Linnworks Application ID"}, "application_secret": {"type": "string", "title": "Application Secret", "description": "Linnworks Application Secret", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (61, 'ClickHouse', 'airbyte/source-clickhouse', '0.1.10', 'https://docs.airbyte.io/integrations/sources/clickhouse', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/cliskhouse.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/clickhouse", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "ClickHouse Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username"], "properties": {"ssl": {"type": "boolean", "title": "SSL Connection", "default": true, "description": "Encrypt data using SSL."}, "host": {"type": "string", "title": "Host", "description": "The host endpoint of the Clickhouse cluster."}, "port": {"type": "integer", "title": "Port", "default": 8123, "maximum": 65536, "minimum": 0, "examples": ["8123"], "description": "The port of the database."}, "database": {"type": "string", "title": "Database", "examples": ["default"], "description": "The name of the database."}, "password": {"type": "string", "title": "Password", "description": "The password associated with this username.", "airbyte_secret": true}, "username": {"type": "string", "title": "Username", "description": "The username which is used to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 1, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (64, 'Bing Ads', 'airbyte/source-bing-ads', '0.1.7', 'https://docs.airbyte.io/integrations/sources/bing-ads', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/bingads.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["auth_method"], "auth_flow_type": "oauth2.0", "predicate_value": "oauth2.0", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"refresh_token": {"type": "string", "path_in_connector_config": ["refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"tenant_id": {"type": "string", "path_in_connector_config": ["tenant_id"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/bing-ads", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Bing Ads Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["developer_token", "client_id", "refresh_token", "reports_start_date", "hourly_reports", "daily_reports", "weekly_reports", "monthly_reports"], "properties": {"client_id": {"type": "string", "order": 1, "title": "Client ID", "description": "The Client ID of your Microsoft Advertising developer application.", "airbyte_secret": true}, "tenant_id": {"type": "string", "order": 0, "title": "Tenant ID", "default": "common", "description": "The Tenant ID of your Microsoft Advertising developer application. Set this to \\"common\\" unless you know you need a different value.", "airbyte_secret": true}, "auth_method": {"type": "string", "const": "oauth2.0"}, "client_secret": {"type": "string", "order": 2, "title": "Client Secret", "default": "", "description": "The Client Secret of your Microsoft Advertising developer application.", "airbyte_secret": true}, "daily_reports": {"type": "boolean", "title": "Enable daily-aggregate reports", "default": false, "description": "Toggle this to enable replicating reports aggregated using a daily time window. More information about report aggregation can be found in <a href=\\"https://docs.airbyte.com/integrations/sources/bing-ads/#report-aggregation\\">the docs</a>."}, "refresh_token": {"type": "string", "order": 3, "title": "Refresh Token", "description": "Refresh Token to renew the expired Access Token.", "airbyte_secret": true}, "hourly_reports": {"type": "boolean", "title": "Enable hourly-aggregate reports", "default": false, "description": "Toggle this to enable replicating reports aggregated using an hourly time window. More information about report aggregation can be found in <a href=\\"https://docs.airbyte.com/integrations/sources/bing-ads/#report-aggregation\\">the docs</a>."}, "weekly_reports": {"type": "boolean", "title": "Enable weekly-aggregate reports", "default": false, "description": "Toggle this to enable replicating reports aggregated using a weekly time window running from Sunday to Saturday. More information about report aggregation can be found in <a href=\\"https://docs.airbyte.com/integrations/sources/bing-ads/#report-aggregation\\">the docs</a>."}, "developer_token": {"type": "string", "order": 4, "title": "Developer Token", "description": "Developer token associated with user. See more info <a href=\\"https://docs.microsoft.com/en-us/advertising/guides/get-started?view=bingads-13#get-developer-token\\"> in the docs</a>.", "airbyte_secret": true}, "monthly_reports": {"type": "boolean", "title": "Enable monthly-aggregate reports", "default": false, "description": "Toggle this to enable replicating reports aggregated using a monthly time window. More information about report aggregation can be found in <a href=\\"https://docs.airbyte.com/integrations/sources/bing-ads/#report-aggregation\\">the docs</a>."}, "reports_start_date": {"type": "string", "order": 5, "title": "Reports replication start date", "format": "date", "default": "2020-01-01", "description": "The start date from which to begin replicating report data. Any data generated before this date will not be replicated in reports. This is a UTC date in YYYY-MM-DD format."}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'beta', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (73, 'Hellobaton', 'airbyte/source-hellobaton', '0.1.0', 'https://docs.airbyte.io/integrations/sources/hellobaton', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Hellobaton Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key", "company"], "properties": {"api_key": {"type": "string", "description": "authentication key required to access the api endpoints", "airbyte_secret": true}, "company": {"type": "string", "examples": ["google", "facebook", "microsoft"], "description": "Company name that generates your base api url"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (80, 'Pipedrive', 'airbyte/source-pipedrive', '0.1.12', 'https://docs.airbyte.io/integrations/sources/pipedrive', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/pipedrive.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/pipedrive", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": ["authorization", "0"], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Pipedrive Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["replication_start_date"], "properties": {"authorization": {"type": "object", "oneOf": [{"type": "object", "title": "Sign in via Pipedrive (OAuth)", "required": ["auth_type", "client_id", "client_secret", "refresh_token"], "properties": {"auth_type": {"type": "string", "const": "Client", "order": 0}, "client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Pipedrive developer application.", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Pipedrive developer application", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "The token for obtaining the new access token.", "airbyte_secret": true}}}, {"type": "object", "title": "API Key Authentication", "required": ["auth_type", "api_token"], "properties": {"api_token": {"type": "string", "title": "API Token", "description": "The Pipedrive API Token.", "airbyte_secret": true}, "auth_type": {"type": "string", "const": "Token", "order": 0}}}], "title": "Authentication Type", "description": "Choose one of the possible authorization method"}, "replication_start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2017-01-25T00:00:00Z"], "description": "UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated. When specified and not None, then stream will behave as incremental"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (83, 'Lemlist', 'airbyte/source-lemlist', '0.1.0', 'https://docs.airbyte.io/integrations/sources/lemlist', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Lemlist Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key"], "properties": {"api_key": {"type": "string", "description": "API key to access your lemlist account.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (86, 'Orb', 'airbyte/source-orb', '0.1.2', 'https://docs.airbyte.io/integrations/sources/orb', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/orb.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.withorb.com/", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Orb Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key"], "properties": {"api_key": {"type": "string", "order": 1, "title": "Orb API Key", "description": "Orb API Key, issued from the Orb admin console.", "airbyte_secret": true}, "start_date": {"type": "string", "order": 2, "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2022-03-01T00:00:00Z"], "description": "UTC date and time in the format 2022-03-01T00:00:00Z. Any data with created_at before this data will not be synced."}, "lookback_window_days": {"type": "integer", "order": 3, "title": "Lookback Window (in days)", "default": 0, "minimum": 0, "description": "When set to N, the connector will always refresh resources created within the past N days. By default, updated objects that are not newly created are not incrementally synced."}, "string_event_properties_keys": {"type": "array", "items": {"type": "string"}, "order": 4, "title": "Event properties keys (string values)", "description": "Property key names to extract from all events, in order to enrich ledger entries corresponding to an event deduction."}, "numeric_event_properties_keys": {"type": "array", "items": {"type": "string"}, "order": 5, "title": "Event properties keys (numeric values)", "description": "Property key names to extract from all events, in order to enrich ledger entries corresponding to an event deduction."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (87, 'Chargify', 'airbyte/source-chargify', '0.1.0', 'https://docs.airbyte.io/integrations/sources/chargify', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/chargify.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/chargify", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Chargify Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key", "domain"], "properties": {"domain": {"type": "string", "description": "Chargify domain. Normally this domain follows the following format companyname.chargify.com"}, "api_key": {"type": "string", "description": "Chargify API Key.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (88, 'Zendesk Chat', 'airbyte/source-zendesk-chat', '0.1.7', 'https://docs.airbyte.io/integrations/sources/zendesk-chat', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/zendesk.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "credentials"], "auth_flow_type": "oauth2.0", "predicate_value": "oauth2.0", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"access_token": {"type": "string", "path_in_connector_config": ["credentials", "access_token"]}, "refresh_token": {"type": "string", "path_in_connector_config": ["credentials", "refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"subdomain": {"type": "string", "path_in_connector_config": ["subdomain"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/zendesk-chat", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Zendesk Chat Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["start_date"], "properties": {"subdomain": {"type": "string", "title": "Subdomain (Optional)", "default": "", "description": "Required if you access Zendesk Chat from a Zendesk Support subdomain."}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2021-02-01T00:00:00Z"], "description": "The date from which you''d like to replicate data for Zendesk Chat API, in the format YYYY-MM-DDT00:00:00Z."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "OAuth2.0", "required": ["credentials"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your OAuth application", "airbyte_secret": true}, "credentials": {"type": "string", "const": "oauth2.0", "order": 0}, "access_token": {"type": "string", "title": "Access Token", "description": "Access Token for making authenticated requests.", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your OAuth application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "Refresh Token to obtain new Access Token, when it''s expired.", "airbyte_secret": true}}}, {"type": "object", "title": "Access Token", "required": ["credentials", "access_token"], "properties": {"credentials": {"type": "string", "const": "access_token", "order": 0}, "access_token": {"type": "string", "title": "Access Token", "description": "The Access Token to make authenticated requests.", "airbyte_secret": true}}}], "title": "Authorization Method"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (92, 'TiDB', 'airbyte/source-tidb', '0.1.1', 'https://docs.airbyte.io/integrations/sources/tidb', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/tidb.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/tidb", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "TiDB Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username"], "properties": {"ssl": {"type": "boolean", "order": 6, "title": "SSL Connection", "default": false, "description": "Encrypt data using SSL."}, "host": {"type": "string", "order": 0, "description": "Hostname of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 4000, "maximum": 65536, "minimum": 0, "examples": ["4000"], "description": "Port of the database."}, "database": {"type": "string", "order": 2, "title": "Database", "description": "Name of the database."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "description": "Username to use to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}, "jdbc_url_params": {"type": "string", "order": 5, "title": "JDBC URL Params", "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3)"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (95, 'Faker', 'airbyte/source-faker', '0.1.4', 'https://docs.airbyte.com/integrations/source-faker', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.com/integrations/sources/faker", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Faker Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["count"], "properties": {"seed": {"type": "integer", "order": 1, "title": "Seed", "default": -1, "description": "Manually control the faker random seed to return the same values on subsequent runs (leave -1 for random)"}, "count": {"type": "integer", "order": 0, "title": "Count", "default": 1000, "minimum": 1, "description": "How many users should be generated in total.  This setting does not apply to the purchases or products stream."}, "records_per_sync": {"type": "integer", "order": 2, "title": "Records Per Sync", "default": 500, "minimum": 1, "description": "How many fake records will be returned for each sync, for each stream?  By default, it will take 2 syncs to create the requested 1000 records."}, "records_per_slice": {"type": "integer", "order": 3, "title": "Records Per Stream Slice", "default": 100, "minimum": 1, "description": "How many fake records will be in each page (stream slice), before a state message is emitted?"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (98, 'Cockroachdb', 'airbyte/source-cockroachdb', '0.1.12', 'https://docs.airbyte.io/integrations/sources/cockroachdb', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/cockroachdb.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/cockroachdb", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Cockroach Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username"], "properties": {"ssl": {"type": "boolean", "order": 5, "title": "Connect using SSL", "default": false, "description": "Encrypt client/server communications for increased security."}, "host": {"type": "string", "order": 0, "title": "Host", "description": "Hostname of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 5432, "maximum": 65536, "minimum": 0, "examples": ["5432"], "description": "Port of the database."}, "database": {"type": "string", "order": 2, "title": "DB Name", "description": "Name of the database."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "title": "User", "description": "Username to use to access the database."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (104, 'Amazon SQS', 'airbyte/source-amazon-sqs', '0.1.0', 'https://docs.airbyte.io/integrations/sources/amazon-sqs', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/amazon-sqs", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Amazon SQS Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["queue_url", "region", "delete_messages"], "properties": {"region": {"enum": ["us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1"], "type": "string", "order": 1, "title": "AWS Region", "description": "AWS Region of the SQS Queue"}, "queue_url": {"type": "string", "order": 0, "title": "Queue URL", "examples": ["https://sqs.eu-west-1.amazonaws.com/1234567890/my-example-queue"], "description": "URL of the SQS Queue"}, "access_key": {"type": "string", "order": 7, "title": "AWS IAM Access Key ID", "examples": ["xxxxxHRNxxx3TBxxxxxx"], "description": "The Access Key ID of the AWS IAM Role to use for pulling messages", "airbyte_secret": true}, "secret_key": {"type": "string", "order": 8, "title": "AWS IAM Secret Key", "examples": ["hu+qE5exxxxT6o/ZrKsxxxxxxBhxxXLexxxxxVKz"], "description": "The Secret Key of the AWS IAM Role to use for pulling messages", "airbyte_secret": true}, "max_wait_time": {"type": "integer", "order": 4, "title": "Max Wait Time", "examples": ["5"], "description": "Max amount of time in seconds to wait for messages in a single poll (20 max)"}, "max_batch_size": {"type": "integer", "order": 3, "title": "Max Batch Size", "examples": ["5"], "description": "Max amount of messages to get in one batch (10 max)"}, "delete_messages": {"type": "boolean", "order": 2, "title": "Delete Messages After Read", "default": false, "description": "If Enabled, messages will be deleted from the SQS Queue after being read. If Disabled, messages are left in the queue and can be read more than once. WARNING: Enabling this option can result in data loss in cases of failure, use with caution, see documentation for more detail. "}, "visibility_timeout": {"type": "integer", "order": 6, "title": "Message Visibility Timeout", "examples": ["15"], "description": "Modify the Visibility Timeout of the individual message from the Queue''s default (seconds)."}, "attributes_to_return": {"type": "string", "order": 5, "title": "Message Attributes To Return", "examples": ["attr1,attr2"], "description": "Comma separated list of Mesage Attribute names to return"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (107, 'Mailgun', 'airbyte/source-mailgun', '0.1.0', 'https://docs.airbyte.io/integrations/sources/mailgun', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mailgun.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/mailgun", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source Mailgun Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["private_key"], "properties": {"start_date": {"type": "string", "title": "Replication Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}$", "examples": ["2020-10-01 00:00:00"], "description": "UTC date and time in the format 2020-10-01 00:00:00. Any data before this date will not be replicated. If omitted, defaults to 3 days ago."}, "private_key": {"type": "string", "title": "Private API Key", "description": "Primary account API key to access your Mailgun data.", "airbyte_secret": true}, "domain_region": {"type": "string", "title": "Domain Region Code", "description": "Domain region code. ''EU'' or ''US'' are possible values. The default is ''US''."}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (110, 'Gitlab', 'airbyte/source-gitlab', '0.1.5', 'https://docs.airbyte.io/integrations/sources/gitlab', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/gitlab.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/gitlab", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source GitLab Singer Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_url", "private_token", "start_date"], "properties": {"groups": {"type": "string", "title": "Groups", "examples": ["airbyte.io"], "description": "Space-delimited list of groups. e.g. airbyte.io."}, "api_url": {"type": "string", "title": "API URL", "examples": ["gitlab.com"], "description": "Please enter your basic URL from GitLab instance."}, "projects": {"type": "string", "title": "Projects", "examples": ["airbyte.io/documentation"], "description": "Space-delimited list of projects. e.g. airbyte.io/documentation meltano/tap-gitlab."}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2021-03-01T00:00:00Z"], "description": "The date from which you''d like to replicate data for GitLab API, in the format YYYY-MM-DDT00:00:00Z. All data generated after this date will be replicated."}, "private_token": {"type": "string", "title": "Private Token", "description": "Log into your GitLab account and then generate a personal Access Token.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (112, 'Dixa', 'airbyte/source-dixa', '0.1.2', 'https://docs.airbyte.io/integrations/sources/dixa', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/dixa.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/dixa", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Dixa Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_token", "start_date"], "properties": {"api_token": {"type": "string", "description": "Dixa API token", "airbyte_secret": true}, "batch_size": {"type": "integer", "default": 31, "pattern": "^[0-9]{1,2}$", "examples": [1, 31], "description": "Number of days to batch into one request. Max 31."}, "start_date": {"type": "string", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["YYYY-MM-DD"], "description": "The connector pulls records updated from this date onwards."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (113, 'Outreach', 'airbyte/source-outreach', '0.1.1', 'https://docs.airbyte.io/integrations/sources/outreach', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/outreach.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/outreach", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source Outreach Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["client_id", "client_secret", "refresh_token", "redirect_uri", "start_date"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Outreach developer application."}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2020-11-16T00:00:00Z"], "description": "The date from which you''d like to replicate data for Outreach API, in the format YYYY-MM-DDT00:00:00Z. All data generated after this date will be replicated."}, "redirect_uri": {"type": "string", "title": "Redirect URI", "description": "A Redirect URI is the location where the authorization server sends the user once the app has been successfully authorized and granted an authorization code or access token."}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Outreach developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "The token for obtaining the new access token.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (114, 'Harness', 'farosai/airbyte-harness-source', '0.1.23', 'https://docs.airbyte.io/integrations/sources/harness', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/harness.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.faros.ai", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Harness Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key", "account_id"], "properties": {"api_key": {"type": "string", "title": "Harness API key", "airbyte_secret": true}, "api_url": {"type": "string", "title": "Harness API URL", "default": "https://app.harness.io", "examples": ["https://my-harness-server.example.com"]}, "page_size": {"type": "number", "title": "Harness Page Size", "default": 100, "description": "number of pipelines (builds) to fetch per call"}, "account_id": {"type": "string", "title": "Harness account ID"}, "cutoff_days": {"type": "number", "title": "Harness Cutoff Days", "default": 90, "description": "Only fetch deployments updated after cutoff"}, "deployment_timeout": {"type": "number", "title": "Harness Deployment Timeout", "default": 24, "description": "Max number of hours to consider for a deployment to be running/queued before giving up on syncing it"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (117, 'Square', 'airbyte/source-square', '0.1.4', 'https://docs.airbyte.io/integrations/sources/square', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/square.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "auth_type"], "auth_flow_type": "oauth2.0", "predicate_value": "Oauth", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"refresh_token": {"type": "string", "path_in_connector_config": ["credentials", "refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/square", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": ["credentials", "0"], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Square Source CDK Specifications", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["is_sandbox"], "properties": {"is_sandbox": {"type": "boolean", "title": "Sandbox", "default": false, "examples": [true, false], "description": "Determines whether to use the sandbox or production environment."}, "start_date": {"type": "string", "title": "Start Date", "default": "2021-01-01", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-01-01"], "description": "UTC date in the format YYYY-MM-DD. Any data before this date will not be replicated. If not set, all data will be replicated."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "Oauth authentication", "required": ["auth_type", "client_id", "client_secret", "refresh_token"], "properties": {"auth_type": {"enum": ["Oauth"], "type": "string", "const": "Oauth", "order": 0, "default": "Oauth"}, "client_id": {"type": "string", "title": "Client ID", "description": "The Square-issued ID of your application", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Square-issued application secret for your application", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "A refresh token generated using the above client ID and secret", "airbyte_secret": true}}}, {"type": "object", "title": "API Key", "required": ["auth_type", "api_key"], "properties": {"api_key": {"type": "string", "title": "API key token", "description": "The API key for a Square application", "airbyte_secret": true}, "auth_type": {"enum": ["Apikey"], "type": "string", "const": "Apikey", "order": 1, "default": "Apikey"}}}], "title": "Credential Type"}, "include_deleted_objects": {"type": "boolean", "title": "Include Deleted Objects", "default": false, "examples": [true, false], "description": "In some streams there is an option to include deleted objects (Items, Categories, Discounts, Taxes)"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (118, 'Microsoft teams', 'airbyte/source-microsoft-teams', '0.2.5', 'https://docs.airbyte.io/integrations/sources/microsoft-teams', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/microsoft-teams.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "auth_type"], "auth_flow_type": "oauth2.0", "predicate_value": "Client", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"refresh_token": {"type": "string", "path_in_connector_config": ["credentials", "refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"tenant_id": {"type": "string", "path_in_connector_config": ["credentials", "tenant_id"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/microsoft-teams", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Microsoft Teams Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["period"], "properties": {"period": {"type": "string", "title": "Period", "examples": ["D7"], "description": "Specifies the length of time over which the Team Device Report stream is aggregated. The supported values are: D7, D30, D90, and D180."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "Authenticate via Microsoft (OAuth 2.0)", "required": ["tenant_id", "client_id", "client_secret", "refresh_token"], "properties": {"auth_type": {"enum": ["Client"], "type": "string", "const": "Client", "order": 0, "default": "Client"}, "client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Microsoft Teams developer application."}, "tenant_id": {"type": "string", "title": "Directory (tenant) ID", "description": "A globally unique identifier (GUID) that is different than your organization name or domain. Follow these steps to obtain: open one of the Teams where you belong inside the Teams Application -> Click on the … next to the Team title -> Click on Get link to team -> Copy the link to the team and grab the tenant ID form the URL"}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Microsoft Teams developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "A Refresh Token to renew the expired Access Token.", "airbyte_secret": true}}, "additionalProperties": false}, {"type": "object", "title": "Authenticate via Microsoft", "required": ["tenant_id", "client_id", "client_secret"], "properties": {"auth_type": {"enum": ["Token"], "type": "string", "const": "Token", "order": 0, "default": "Token"}, "client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Microsoft Teams developer application."}, "tenant_id": {"type": "string", "title": "Directory (tenant) ID", "description": "A globally unique identifier (GUID) that is different than your organization name or domain. Follow these steps to obtain: open one of the Teams where you belong inside the Teams Application -> Click on the … next to the Team title -> Click on Get link to team -> Copy the link to the team and grab the tenant ID form the URL"}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Microsoft Teams developer application.", "airbyte_secret": true}}, "additionalProperties": false}], "title": "Authentication mechanism", "description": "Choose how to authenticate to Microsoft"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (120, 'Plaid', 'airbyte/source-plaid', '0.3.1', 'https://docs.airbyte.io/integrations/sources/plaid', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/plaid.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://plaid.com/docs/api/", "supportsNormalization": false, "connectionSpecification": {"type": "object", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["access_token", "api_key", "client_id", "plaid_env"], "properties": {"api_key": {"type": "string", "title": "API Key", "description": "The Plaid API key to use to hit the API.", "airbyte_secret": true}, "client_id": {"type": "string", "title": "Client ID", "description": "The Plaid client id"}, "plaid_env": {"enum": ["sandbox", "development", "production"], "type": "string", "title": "Plaid Environment", "description": "The Plaid environment"}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-03-01"], "description": "The date from which you''d like to replicate data for Plaid in the format YYYY-MM-DD. All data generated after this date will be replicated."}, "access_token": {"type": "string", "title": "Access Token", "description": "The end-user''s Link access token."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (123, 'RKI Covid', 'airbyte/source-rki-covid', '0.1.1', 'https://docs.airbyte.io/integrations/sources/rki-covid', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.com/integrations/sources/rki-covid", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "RKI Covid Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["start_date"], "properties": {"start_date": {"type": "string", "order": 1, "title": "Start Date", "description": "UTC date in the format 2017-01-25. Any data before this date will not be replicated."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (124, 'Pivotal Tracker', 'airbyte/source-pivotal-tracker', '0.1.0', 'https://docs.airbyte.io/integrations/sources/pivotal-tracker', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Pivotal Tracker Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_token"], "properties": {"api_token": {"type": "string", "examples": ["5c054d0de3440452190fdc5d5a04d871"], "description": "Pivotal Tracker API token"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (125, 'YouTube Analytics', 'airbyte/source-youtube-analytics', '0.1.0', 'https://docs.airbyte.io/integrations/sources/youtube-analytics', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/youtube.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/youtube-analytics", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": ["credentials"], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "YouTube Analytics Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["credentials"], "properties": {"credentials": {"type": "object", "title": "Authenticate via OAuth 2.0", "required": ["client_id", "client_secret", "refresh_token"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your developer application", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The client secret of your developer application", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "A refresh token generated using the above client ID and secret", "airbyte_secret": true}}, "additionalProperties": false}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (129, 'My Hours', 'airbyte/source-my-hours', '0.1.1', 'https://docs.airbyte.io/integrations/sources/my-hours', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/my-hours.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/my-hours", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "My Hours Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["email", "password", "start_date"], "properties": {"email": {"type": "string", "title": "Email", "example": "john@doe.com", "description": "Your My Hours username"}, "password": {"type": "string", "title": "Password", "description": "The password associated to the username", "airbyte_secret": true}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["%Y-%m-%d", "2016-01-01"], "description": "Start date for collecting time logs"}, "logs_batch_size": {"type": "integer", "title": "Time logs batch size", "default": 30, "maximum": 365, "minimum": 1, "examples": [30], "description": "Pagination size used for retrieving logs in days"}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (130, 'Cart.com', 'airbyte/source-cart', '0.1.5', 'https://docs.airbyte.io/integrations/sources/cart', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/cart.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/cart", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Cart.com Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["access_token", "start_date", "store_name"], "properties": {"start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2021-01-01T00:00:00Z"], "description": "The date from which you''d like to replicate the data"}, "store_name": {"type": "string", "title": "Store Name", "description": "The name of Cart.com Online Store. All API URLs start with https://[mystorename.com]/api/v1/, where [mystorename.com] is the domain name of your store."}, "access_token": {"type": "string", "title": "Access Token", "description": "Access Token for making authenticated requests.", "airbyte_secret": true}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (131, 'TalkDesk Explore', 'airbyte/source-talkdesk-explore', '0.1.0', 'https://docs.airbyte.io/integrations/sources/talkdesk-explore', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/talkdesk-explore.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Talkdesk Explore API Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["start_date", "auth_url", "api_key"], "properties": {"api_key": {"type": "string", "order": 3, "title": "API KEY", "description": "Talkdesk API key."}, "auth_url": {"type": "string", "order": 2, "title": "AUTH URL", "examples": ["https://xxxxxx.talkdeskid.com/oauth/token?grant_type=client_credentials"], "description": "Talkdesk Auth URL. Only ''client_credentials'' auth type supported at the moment."}, "timezone": {"type": "string", "order": 1, "title": "TIMEZONE", "default": "UTC", "examples": ["Europe/London", "America/Los_Angeles"], "description": "Timezone to use when generating reports. Only IANA timezones are supported (https://nodatime.org/TimeZones)"}, "start_date": {"type": "string", "order": 0, "title": "START DATE", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}$", "examples": ["2020-10-15T00:00:00"], "description": "The date from which you''d like to replicate data for Talkdesk Explore API, in the format YYYY-MM-DDT00:00:00. All data generated after this date will be replicated."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (132, 'VictorOps', 'farosai/airbyte-victorops-source', '0.1.23', 'https://docs.airbyte.io/integrations/sources/victorops', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/victorops.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.faros.ai", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "VictorOps Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["apiId", "apiKey"], "properties": {"apiId": {"type": "string", "title": "VictorOps API ID", "airbyte_secret": true}, "apiKey": {"type": "string", "title": "VictorOps API key", "airbyte_secret": true}, "pageLimit": {"type": "number", "title": "VictorOps Page Limit", "default": 100}, "currentPhase": {"type": "string", "title": "VictorOps Current Phase", "default": "triggered,acknowledged,resolved"}, "maxContentLength": {"type": "number", "title": "VictorOps Content Length", "default": 500000, "description": "VictorOps API response content length limit, try increasing if ''RequestError'' is encountered."}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (133, 'MySQL', 'airbyte/destination-mysql', '0.1.18', 'https://docs.airbyte.io/integrations/destinations/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mysql.svg', 'destination', null, '{"supportsDBT": true, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/mysql", "supportsIncremental": true, "supportsNormalization": true, "connectionSpecification": {"type": "object", "title": "MySQL Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "username", "database"], "properties": {"ssl": {"type": "boolean", "order": 5, "title": "SSL Connection", "default": true, "description": "Encrypt data using SSL."}, "host": {"type": "string", "order": 0, "title": "Host", "description": "Hostname of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 3306, "maximum": 65536, "minimum": 0, "examples": ["3306"], "description": "Port of the database."}, "database": {"type": "string", "order": 2, "title": "DB Name", "description": "Name of the database."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "title": "User", "description": "Username to use to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}, "jdbc_url_params": {"type": "string", "order": 6, "title": "JDBC URL Params", "description": "Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3)."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (137, 'Shopify', 'airbyte/source-shopify', '0.1.37', 'https://docs.airbyte.io/integrations/sources/shopify', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/shopify.svg', 'source', 'api', '{"supportsDBT": false, "advanced_auth": {"predicate_key": ["credentials", "auth_method"], "auth_flow_type": "oauth2.0", "predicate_value": "oauth2.0", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"access_token": {"type": "string", "path_in_connector_config": ["credentials", "access_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"shop": {"type": "string", "path_in_connector_config": ["shop"]}}, "additionalProperties": false}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/shopify", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Shopify Source CDK Specifications", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["shop", "start_date"], "properties": {"shop": {"type": "string", "order": 1, "title": "Shopify Store", "description": "The name of your Shopify store found in the URL. For example, if your URL was https://NAME.myshopify.com, then the name would be ''NAME''."}, "start_date": {"type": "string", "order": 3, "title": "Replication Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}$", "examples": ["2021-01-01"], "description": "The date you would like to replicate data from. Format: YYYY-MM-DD. Any data before this date will not be replicated."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "OAuth2.0", "required": ["auth_method"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of the Shopify developer application.", "airbyte_secret": true}, "auth_method": {"type": "string", "const": "oauth2.0", "order": 0}, "access_token": {"type": "string", "title": "Access Token", "description": "The Access Token for making authenticated requests.", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of the Shopify developer application.", "airbyte_secret": true}}, "description": "OAuth2.0"}, {"type": "object", "title": "API Password", "required": ["auth_method", "api_password"], "properties": {"auth_method": {"type": "string", "const": "api_password", "order": 0}, "api_password": {"type": "string", "title": "API Password", "description": "The API Password for your private application in the `Shopify` store.", "airbyte_secret": true}}, "description": "API Password Auth"}], "order": 2, "title": "Shopify Authorization Method", "description": "The authorization method to use to retrieve data from Shopify"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (139, 'SalesLoft', 'airbyte/source-salesloft', '0.1.3', 'https://docs.airbyte.io/integrations/sources/salesloft', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/salesloft.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/salesloft", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Source Salesloft Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["client_id", "client_secret", "refresh_token", "start_date"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Salesloft developer application."}, "start_date": {"type": "string", "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2020-11-16T00:00:00Z"], "description": "The date from which you''d like to replicate data for Salesloft API, in the format YYYY-MM-DDT00:00:00Z. All data generated after this date will be replicated."}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Salesloft developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "The token for obtaining a new access token.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (140, 'Lever Hiring', 'airbyte/source-lever-hiring', '0.1.2', 'https://docs.airbyte.io/integrations/sources/lever-hiring', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/leverhiring.svg', 'source', 'api', '{"supportsDBT": false, "changelogUrl": "https://docs.airbyte.io/integrations/sources/lever-hiring#changelog", "advanced_auth": {"predicate_key": ["credentials", "auth_type"], "auth_flow_type": "oauth2.0", "predicate_value": "Client", "oauth_config_specification": {"complete_oauth_output_specification": {"type": "object", "properties": {"refresh_token": {"type": "string", "path_in_connector_config": ["credentials", "refresh_token"]}}, "additionalProperties": false}, "complete_oauth_server_input_specification": {"type": "object", "properties": {"client_id": {"type": "string"}, "client_secret": {"type": "string"}}, "additionalProperties": false}, "complete_oauth_server_output_specification": {"type": "object", "properties": {"client_id": {"type": "string", "path_in_connector_config": ["credentials", "client_id"]}, "client_secret": {"type": "string", "path_in_connector_config": ["credentials", "client_secret"]}}, "additionalProperties": false}, "oauth_user_input_from_connector_config_specification": {"type": "object", "properties": {"environment": {"type": "string", "path_in_connector_config": ["environment"]}}}}}, "documentationUrl": "https://docs.airbyte.io/integrations/sources/lever-hiring", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": ["credentials", "0"], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Lever Hiring Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["start_date"], "properties": {"start_date": {"type": "string", "order": 0, "title": "Start Date", "pattern": "^[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z$", "examples": ["2021-03-01T00:00:00Z"], "description": "UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated. Note that it will be used only in the following incremental streams: comments, commits, and issues."}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "Authenticate via Lever (OAuth)", "required": ["refresh_token"], "properties": {"auth_type": {"enum": ["Client"], "type": "string", "const": "Client", "order": 0, "default": "Client"}, "client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Lever Hiring developer application."}, "option_title": {"type": "string", "const": "OAuth Credentials", "title": "Credentials Title", "description": "OAuth Credentials"}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Lever Hiring developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "The token for obtaining new access token.", "airbyte_secret": true}}}], "order": 3, "title": "Authentication Mechanism", "description": "Choose how to authenticate to Lever Hiring."}, "environment": {"enum": ["Production", "Sandbox"], "type": "string", "order": 1, "title": "Environment", "default": "Sandbox", "description": "The environment in which you''d like to replicate data for Lever. This is used to determine which Lever API endpoint to use."}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (143, 'SFTP', 'airbyte/source-sftp', '0.1.1', 'https://docs.airbyte.com/integrations/sources/sftp', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', 'file', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/source/sftp", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "SFTP Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["user", "host", "port"], "properties": {"host": {"type": "string", "order": 1, "title": "Host Address", "examples": ["www.host.com", "192.0.2.1"], "description": "The server host address"}, "port": {"type": "integer", "order": 2, "title": "Port", "default": 22, "examples": ["22"], "description": "The server port"}, "user": {"type": "string", "order": 0, "title": "User Name", "description": "The server user"}, "file_types": {"type": "string", "order": 4, "title": "File types", "default": "csv,json", "examples": ["csv,json", "csv"], "description": "Coma separated file types. Currently only ''csv'' and ''json'' types are supported."}, "credentials": {"type": "object", "oneOf": [{"title": "Password Authentication", "required": ["auth_method", "auth_user_password"], "properties": {"auth_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through password authentication"}, "auth_user_password": {"type": "string", "order": 1, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}, {"title": "SSH Key Authentication", "required": ["auth_method", "auth_ssh_key"], "properties": {"auth_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through ssh key"}, "auth_ssh_key": {"type": "string", "order": 1, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}}}], "order": 3, "title": "Authentication *", "description": "The server authentication method"}, "folder_path": {"type": "string", "order": 5, "title": "Folder Path (Optional)", "default": "", "examples": ["/logs/2022"], "description": "The directory to search files for sync"}, "file_pattern": {"type": "string", "order": 6, "title": "File Pattern (Optional)", "default": "", "examples": ["log-([0-9]{4})([0-9]{2})([0-9]{2}) - This will filter files which  `log-yearmmdd`"], "description": "The regular expression to specify files for sync in a chosen Folder Path"}}, "additionalProperties": true}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (144, 'Delighted', 'airbyte/source-delighted', '0.1.3', 'https://docs.airbyte.io/integrations/sources/delighted', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/delighted.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docsurl.com", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Delighted Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["since", "api_key"], "properties": {"since": {"type": "integer", "examples": [1625328167], "description": "An Unix timestamp to retrieve records created on or after this time."}, "api_key": {"type": "string", "description": "A Delighted API key.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (145, 'Tempo', 'airbyte/source-tempo', '0.2.5', 'https://docs.airbyte.io/integrations/sources/tempo', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/tempo.svg', 'source', 'api', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/sources/", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Tempo Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_token"], "properties": {"api_token": {"type": "string", "title": "API token", "description": "Tempo API Token. Go to Tempo>Settings, scroll down to Data Access and select API integration.", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (148, 'Redshift', 'airbyte/source-redshift', '0.3.10', 'https://docs.airbyte.io/integrations/sources/redshift', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/redshift.svg', 'source', 'database', '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/redshift", "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Redshift Source Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username", "password"], "properties": {"host": {"type": "string", "order": 1, "title": "Host", "description": "Host Endpoint of the Redshift Cluster (must include the cluster-id, region and end with .redshift.amazonaws.com)."}, "port": {"type": "integer", "order": 2, "title": "Port", "default": 5439, "maximum": 65536, "minimum": 0, "examples": ["5439"], "description": "Port of the database."}, "schemas": {"type": "array", "items": {"type": "string"}, "order": 4, "title": "Schemas", "examples": ["public"], "minItems": 0, "description": "The list of schemas to sync from. Specify one or more explicitly or keep empty to process all schemas. Schema names are case sensitive.", "uniqueItems": true}, "database": {"type": "string", "order": 3, "title": "Database", "examples": ["master"], "description": "Name of the database."}, "password": {"type": "string", "order": 6, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 5, "title": "Username", "description": "Username to use to access the database."}}, "additionalProperties": false}, "supported_destination_sync_modes": []}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (150, 'Google Sheets', 'airbyte/destination-google-sheets', '0.1.0', 'https://docs.airbyte.io/integrations/destinations/google-sheets', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/google-sheets.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/google-sheets", "authSpecification": {"auth_type": "oauth2.0", "oauth2Specification": {"rootObject": ["credentials"], "oauthFlowInitParameters": [["client_id"], ["client_secret"]], "oauthFlowOutputParameters": [["refresh_token"]]}}, "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Destination Google Sheets", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["spreadsheet_id", "credentials"], "properties": {"credentials": {"type": "object", "title": "* Authentication via Google (OAuth)", "required": ["client_id", "client_secret", "refresh_token"], "properties": {"client_id": {"type": "string", "title": "Client ID", "description": "The Client ID of your Google Sheets developer application.", "airbyte_secret": true}, "client_secret": {"type": "string", "title": "Client Secret", "description": "The Client Secret of your Google Sheets developer application.", "airbyte_secret": true}, "refresh_token": {"type": "string", "title": "Refresh Token", "description": "The token for obtaining new access token.", "airbyte_secret": true}}, "description": "Google API Credentials for connecting to Google Sheets and Google Drive APIs"}, "spreadsheet_id": {"type": "string", "title": "Spreadsheet Link", "examples": ["https://docs.google.com/spreadsheets/d/1hLd9Qqti3UyLXZB2aFfUWDT7BG/edit"], "description": "The link to your spreadsheet. See <a href=''https://docs.airbyte.com/integrations/destinations/google-sheets#sheetlink''>this guide</a> for more details."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append", "append_dedup"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (151, 'E2E Testing', 'airbyte/destination-e2e-test', '0.2.2', 'https://docs.airbyte.io/integrations/destinations/e2e-test', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/airbyte.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/e2e-test", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "oneOf": [{"title": "Logging", "required": ["type", "logging_config"], "properties": {"type": {"type": "string", "const": "LOGGING", "default": "LOGGING"}, "logging_config": {"type": "object", "oneOf": [{"type": "object", "title": "First N Entries", "required": ["logging_type", "max_entry_count"], "properties": {"logging_type": {"enum": ["FirstN"], "type": "string", "default": "FirstN"}, "max_entry_count": {"type": "number", "title": "N", "default": 100, "maximum": 1000, "minimum": 1, "examples": [100], "description": "Number of entries to log. This destination is for testing only. So it won''t make sense to log infinitely. The maximum is 1,000 entries."}}, "description": "Log first N entries per stream."}, {"type": "object", "title": "Every N-th Entry", "required": ["logging_type", "nth_entry_to_log", "max_entry_count"], "properties": {"logging_type": {"enum": ["EveryNth"], "type": "string", "default": "EveryNth"}, "max_entry_count": {"type": "number", "title": "Max Log Entries", "default": 100, "maximum": 1000, "minimum": 1, "examples": [100], "description": "Max number of entries to log. This destination is for testing only. So it won''t make sense to log infinitely. The maximum is 1,000 entries."}, "nth_entry_to_log": {"type": "number", "title": "N", "example": [3], "maximum": 1000, "minimum": 1, "description": "The N-th entry to log for each stream. N starts from 1. For example, when N = 1, every entry is logged; when N = 2, every other entry is logged; when N = 3, one out of three entries is logged."}}, "description": "For each stream, log every N-th entry with a maximum cap."}, {"type": "object", "title": "Random Sampling", "required": ["logging_type", "sampling_ratio", "max_entry_count"], "properties": {"seed": {"type": "number", "title": "Random Number Generator Seed", "examples": [1900], "description": "When the seed is unspecified, the current time millis will be used as the seed."}, "logging_type": {"enum": ["RandomSampling"], "type": "string", "default": "RandomSampling"}, "sampling_ratio": {"type": "number", "title": "Sampling Ratio", "default": 0.001, "maximum": 1, "minimum": 0, "examples": [0.001], "description": "A positive floating number smaller than 1."}, "max_entry_count": {"type": "number", "title": "Max Log Entries", "default": 100, "maximum": 1000, "minimum": 1, "examples": [100], "description": "Max number of entries to log. This destination is for testing only. So it won''t make sense to log infinitely. The maximum is 1,000 entries."}}, "description": "For each stream, randomly log a percentage of the entries with a maximum cap."}], "title": "Logging Configuration", "description": "Configurate how the messages are logged."}}}, {"title": "Silent", "required": ["type"], "properties": {"type": {"type": "string", "const": "SILENT", "default": "SILENT"}}}, {"title": "Throttled", "required": ["type", "millis_per_record"], "properties": {"type": {"type": "string", "const": "THROTTLED", "default": "THROTTLED"}, "millis_per_record": {"type": "integer", "description": "Number of milli-second to pause in between records."}}}, {"title": "Failing", "required": ["type", "num_messages"], "properties": {"type": {"type": "string", "const": "FAILING", "default": "FAILING"}, "num_messages": {"type": "integer", "description": "Number of messages after which to fail."}}}], "title": "E2E Test Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#"}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 0, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (152, 'MariaDB ColumnStore', 'airbyte/destination-mariadb-columnstore', '0.1.4', 'https://docs.airbyte.io/integrations/destinations/mariadb-columnstore', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mariadb.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/mariadb-columnstore", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "MariaDB Columnstore Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "username", "database"], "properties": {"host": {"type": "string", "order": 0, "title": "Host", "description": "The Hostname of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 3306, "maximum": 65536, "minimum": 0, "examples": ["3306"], "description": "The Port of the database."}, "database": {"type": "string", "order": 2, "title": "Database", "description": "Name of the database."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "The Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "title": "Username", "description": "The Username which is used to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (153, 'Kafka', 'airbyte/destination-kafka', '0.1.8', 'https://docs.airbyte.io/integrations/destinations/kafka', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/kafka.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/kafka", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Kafka Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["bootstrap_servers", "topic_pattern", "protocol", "acks", "enable_idempotence", "compression_type", "batch_size", "linger_ms", "max_in_flight_requests_per_connection", "client_dns_lookup", "buffer_memory", "max_request_size", "retries", "socket_connection_setup_timeout_ms", "socket_connection_setup_timeout_max_ms", "max_block_ms", "request_timeout_ms", "delivery_timeout_ms", "send_buffer_bytes", "receive_buffer_bytes"], "properties": {"acks": {"enum": ["0", "1", "all"], "type": "string", "title": "ACKs", "default": "1", "description": "The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the  durability of records that are sent."}, "retries": {"type": "integer", "title": "Retries", "examples": [2147483647], "description": "Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error."}, "protocol": {"type": "object", "oneOf": [{"title": "PLAINTEXT", "required": ["security_protocol"], "properties": {"security_protocol": {"enum": ["PLAINTEXT"], "type": "string", "default": "PLAINTEXT"}}}, {"title": "SASL PLAINTEXT", "required": ["security_protocol", "sasl_mechanism", "sasl_jaas_config"], "properties": {"sasl_mechanism": {"enum": ["PLAIN"], "type": "string", "title": "SASL Mechanism", "default": "PLAIN", "description": "SASL mechanism used for client connections. This may be any mechanism for which a security provider is available."}, "sasl_jaas_config": {"type": "string", "title": "SASL JAAS Config", "default": "", "description": "JAAS login context parameters for SASL connections in the format used by JAAS configuration files.", "airbyte_secret": true}, "security_protocol": {"enum": ["SASL_PLAINTEXT"], "type": "string", "default": "SASL_PLAINTEXT"}}}, {"title": "SASL SSL", "required": ["security_protocol", "sasl_mechanism", "sasl_jaas_config"], "properties": {"sasl_mechanism": {"enum": ["GSSAPI", "OAUTHBEARER", "SCRAM-SHA-256", "SCRAM-SHA-512", "PLAIN"], "type": "string", "title": "SASL Mechanism", "default": "GSSAPI", "description": "SASL mechanism used for client connections. This may be any mechanism for which a security provider is available."}, "sasl_jaas_config": {"type": "string", "title": "SASL JAAS Config", "default": "", "description": "JAAS login context parameters for SASL connections in the format used by JAAS configuration files.", "airbyte_secret": true}, "security_protocol": {"enum": ["SASL_SSL"], "type": "string", "default": "SASL_SSL"}}}], "title": "Protocol", "description": "Protocol used to communicate with brokers."}, "client_id": {"type": "string", "title": "Client ID", "examples": ["airbyte-producer"], "description": "An ID string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging."}, "linger_ms": {"type": "string", "title": "Linger ms", "examples": [0], "description": "The producer groups together any records that arrive in between request transmissions into a single batched request."}, "batch_size": {"type": "integer", "title": "Batch Size", "examples": [16384], "description": "The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition."}, "test_topic": {"type": "string", "title": "Test Topic", "examples": ["test.topic"], "description": "Topic to test if Airbyte can produce messages."}, "max_block_ms": {"type": "string", "title": "Max Block ms", "examples": [60000], "description": "The configuration controls how long the KafkaProducer''s send(), partitionsFor(), initTransactions(), sendOffsetsToTransaction(), commitTransaction() and abortTransaction() methods will block."}, "buffer_memory": {"type": "string", "title": "Buffer Memory", "examples": 33554432, "description": "The total bytes of memory the producer can use to buffer records waiting to be sent to the server."}, "sync_producer": {"type": "boolean", "title": "Sync Producer", "default": false, "description": "Wait synchronously until the record has been sent to Kafka."}, "topic_pattern": {"type": "string", "title": "Topic Pattern", "examples": ["sample.topic", "{namespace}.{stream}.sample"], "description": "Topic pattern in which the records will be sent. You can use patterns like ''{namespace}'' and/or ''{stream}'' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention."}, "compression_type": {"enum": ["none", "gzip", "snappy", "lz4", "zstd"], "type": "string", "title": "Compression Type", "default": "none", "description": "The compression type for all data generated by the producer."}, "max_request_size": {"type": "integer", "title": "Max Request Size", "examples": [1048576], "description": "The maximum size of a request in bytes."}, "bootstrap_servers": {"type": "string", "title": "Bootstrap Servers", "examples": ["kafka-broker1:9092,kafka-broker2:9092"], "description": "A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping&mdash;this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2,...</code>. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down)."}, "client_dns_lookup": {"enum": ["default", "use_all_dns_ips", "resolve_canonical_bootstrap_servers_only", "use_all_dns_ips"], "type": "string", "title": "Client DNS Lookup", "default": "use_all_dns_ips", "description": "Controls how the client uses DNS lookups. If set to use_all_dns_ips, connect to each returned IP address in sequence until a successful connection is established. After a disconnection, the next IP is used. Once all IPs have been used once, the client resolves the IP(s) from the hostname again. If set to resolve_canonical_bootstrap_servers_only, resolve each bootstrap address into a list of canonical names. After the bootstrap phase, this behaves the same as use_all_dns_ips. If set to default (deprecated), attempt to connect to the first IP address returned by the lookup, even if the lookup returns multiple IP addresses."}, "send_buffer_bytes": {"type": "integer", "title": "Send Buffer bytes", "examples": [131072], "description": "The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used."}, "enable_idempotence": {"type": "boolean", "title": "Enable Idempotence", "default": false, "description": "When set to ''true'', the producer will ensure that exactly one copy of each message is written in the stream. If ''false'', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream."}, "request_timeout_ms": {"type": "integer", "title": "Request Timeout", "examples": [30000], "description": "The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."}, "delivery_timeout_ms": {"type": "integer", "title": "Delivery Timeout", "examples": [120000], "description": "An upper bound on the time to report success or failure after a call to ''send()'' returns."}, "receive_buffer_bytes": {"type": "integer", "title": "Receive Buffer bytes", "examples": [32768], "description": "The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used."}, "socket_connection_setup_timeout_ms": {"type": "string", "title": "Socket Connection Setup Timeout", "examples": [10000], "description": "The amount of time the client will wait for the socket connection to be established."}, "max_in_flight_requests_per_connection": {"type": "integer", "title": "Max in Flight Requests per Connection", "examples": [5], "description": "The maximum number of unacknowledged requests the client will send on a single connection before blocking. Can be greater than 1, and the maximum value supported with idempotency is 5."}, "socket_connection_setup_timeout_max_ms": {"type": "string", "title": "Socket Connection Setup Max Timeout", "examples": [30000], "description": "The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (154, 'ElasticSearch', 'airbyte/destination-elasticsearch', '0.1.2', 'https://docs.airbyte.io/integrations/destinations/elasticsearch', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/elasticsearch.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/elasticsearch", "supportsNamespaces": true, "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Elasticsearch Connection Configuration", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["endpoint"], "properties": {"upsert": {"type": "boolean", "title": "Upsert Records", "default": true, "description": "If a primary key identifier is defined in the source, an upsert will be performed using the primary key value as the elasticsearch doc id. Does not support composite primary keys."}, "endpoint": {"type": "string", "title": "Server Endpoint", "description": "The full url of the Elasticsearch server"}, "authenticationMethod": {"type": "object", "oneOf": [{"title": "None", "required": ["method"], "properties": {"method": {"type": "string", "const": "none"}}, "description": "No authentication will be used", "additionalProperties": false}, {"title": "Api Key/Secret", "required": ["method", "apiKeyId", "apiKeySecret"], "properties": {"method": {"type": "string", "const": "secret"}, "apiKeyId": {"type": "string", "title": "API Key ID", "description": "The Key ID to used when accessing an enterprise Elasticsearch instance."}, "apiKeySecret": {"type": "string", "title": "API Key Secret", "description": "The secret associated with the API Key ID.", "airbyte_secret": true}}, "description": "Use a api key and secret combination to authenticate", "additionalProperties": false}, {"title": "Username/Password", "required": ["method", "username", "password"], "properties": {"method": {"type": "string", "const": "basic"}, "password": {"type": "string", "title": "Password", "description": "Basic auth password to access a secure Elasticsearch server", "airbyte_secret": true}, "username": {"type": "string", "title": "Username", "description": "Basic auth username to access a secure Elasticsearch server"}}, "description": "Basic auth header with a username and password", "additionalProperties": false}], "title": "Authentication Method", "description": "The type of authentication to be used"}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (156, 'Amazon SQS', 'airbyte/destination-amazon-sqs', '0.1.0', 'https://docs.airbyte.io/integrations/destinations/amazon-sqs', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/amazonsqs.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/amazon-sqs", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Destination Amazon Sqs", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["queue_url", "region"], "properties": {"region": {"enum": ["us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1"], "type": "string", "order": 1, "title": "AWS Region", "description": "AWS Region of the SQS Queue"}, "queue_url": {"type": "string", "order": 0, "title": "Queue URL", "examples": ["https://sqs.eu-west-1.amazonaws.com/1234567890/my-example-queue"], "description": "URL of the SQS Queue"}, "access_key": {"type": "string", "order": 3, "title": "AWS IAM Access Key ID", "examples": ["xxxxxHRNxxx3TBxxxxxx"], "description": "The Access Key ID of the AWS IAM Role to use for sending  messages", "airbyte_secret": true}, "secret_key": {"type": "string", "order": 4, "title": "AWS IAM Secret Key", "examples": ["hu+qE5exxxxT6o/ZrKsxxxxxxBhxxXLexxxxxVKz"], "description": "The Secret Key of the AWS IAM Role to use for sending messages", "airbyte_secret": true}, "message_delay": {"type": "integer", "order": 2, "title": "Message Delay", "examples": ["15"], "description": "Modify the Message Delay of the individual message from the Queue''s default (seconds)."}, "message_body_key": {"type": "string", "order": 5, "title": "Message Body Key", "examples": ["myDataPath"], "description": "Use this property to extract the contents of the named key in the input record to use as the SQS message body. If not set, the entire content of the input record data is used as the message body."}, "message_group_id": {"type": "string", "order": 6, "title": "Message Group Id", "examples": ["my-fifo-group"], "description": "The tag that specifies that a message belongs to a specific message group. This parameter applies only to, and is REQUIRED by, FIFO queues."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (159, 'MQTT', 'airbyte/destination-mqtt', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/mqtt', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mqtt.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/mqtt", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "MQTT Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["broker_host", "broker_port", "use_tls", "topic_pattern", "publisher_sync", "connect_timeout", "automatic_reconnect", "clean_session", "message_retained", "message_qos"], "properties": {"client": {"type": "string", "title": "Client ID", "examples": ["airbyte-client1"], "description": "A client identifier that is unique on the server being connected to."}, "use_tls": {"type": "boolean", "title": "Use TLS", "default": false, "description": "Whether to use TLS encryption on the connection."}, "password": {"type": "string", "title": "Password", "description": "Password to use for the connection."}, "username": {"type": "string", "title": "Username", "description": "User name to use for the connection."}, "topic_test": {"type": "string", "title": "Test topic", "examples": ["test/topic"], "description": "Topic to test if Airbyte can produce messages."}, "broker_host": {"type": "string", "title": "MQTT broker host", "description": "Host of the broker to connect to."}, "broker_port": {"type": "integer", "title": "MQTT broker port", "description": "Port of the broker."}, "message_qos": {"enum": ["AT_MOST_ONCE", "AT_LEAST_ONCE", "EXACTLY_ONCE"], "title": "Message QoS", "default": "AT_LEAST_ONCE", "description": "Quality of service used for each message to be delivered."}, "clean_session": {"type": "boolean", "title": "Clean session", "default": true, "description": "Whether the client and server should remember state across restarts and reconnects."}, "topic_pattern": {"type": "string", "title": "Topic pattern", "examples": ["sample.topic", "{namespace}/{stream}/sample"], "description": "Topic pattern in which the records will be sent. You can use patterns like ''{namespace}'' and/or ''{stream}'' to send the message to a specific topic based on these values. Notice that the topic name will be transformed to a standard naming convention."}, "publisher_sync": {"type": "boolean", "title": "Sync publisher", "default": false, "description": "Wait synchronously until the record has been sent to the broker."}, "connect_timeout": {"type": "integer", "title": "Connect timeout", "default": 30, "description": " Maximum time interval (in seconds) the client will wait for the network connection to the MQTT server to be established."}, "message_retained": {"type": "boolean", "title": "Message retained", "default": false, "description": "Whether or not the publish message should be retained by the messaging engine."}, "automatic_reconnect": {"type": "boolean", "title": "Automatic reconnect", "default": true, "description": "Whether the client will automatically attempt to reconnect to the server if the connection is lost."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (160, 'RabbitMQ', 'airbyte/destination-rabbitmq', '0.1.0', 'https://docs.airbyte.io/integrations/destinations/rabbitmq', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/pulsar.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/rabbitmq", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Destination Rabbitmq", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "routing_key"], "properties": {"ssl": {"type": "boolean", "default": true, "description": "SSL enabled."}, "host": {"type": "string", "description": "The RabbitMQ host name."}, "port": {"type": "integer", "description": "The RabbitMQ port."}, "exchange": {"type": "string", "description": "The exchange name."}, "password": {"type": "string", "description": "The password to connect."}, "username": {"type": "string", "description": "The username to connect."}, "routing_key": {"type": "string", "description": "The routing key."}, "virtual_host": {"type": "string", "description": "The RabbitMQ virtual host name."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (161, 'Rockset', 'airbyte/destination-rockset', '0.1.2', 'https://docs.airbyte.io/integrations/destinations/rockset', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/rockset", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Rockset Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["api_key", "workspace"], "properties": {"api_key": {"type": "string", "order": 0, "title": "Api Key", "description": "Rockset api key", "airbyte_secret": true}, "workspace": {"type": "string", "order": 1, "title": "Workspace", "default": "commons", "examples": ["commons", "my_workspace"], "description": "The Rockset workspace in which collections will be created + written to.", "airbyte_secret": false}, "api_server": {"type": "string", "order": 2, "title": "Api Server", "default": "https://api.rs2.usw2.rockset.com", "pattern": "^https:\\/\\/.*.rockset.com$", "description": "Rockset api URL", "airbyte_secret": false}}, "additionalProperties": false}, "supported_destination_sync_modes": ["append", "overwrite"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (162, 'Chargify (Keen)', 'airbyte/destination-keen', '0.2.2', 'https://docs.airbyte.io/integrations/destinations/keen', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/chargify.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/keen", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Keen Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["project_id", "api_key"], "properties": {"api_key": {"type": "string", "title": "API Key", "examples": ["ABCDEFGHIJKLMNOPRSTUWXYZ"], "description": "To get Keen Master API Key, navigate to the Access tab from the left-hand, side panel and check the Project Details section.", "airbyte_secret": true}, "project_id": {"type": "string", "title": "Project ID", "examples": ["58b4acc22ba938934e888322e"], "description": "To get Keen Project ID, navigate to the Access tab from the left-hand, side panel and check the Project Details section."}, "infer_timestamp": {"type": "boolean", "title": "Infer Timestamp", "default": true, "description": "Allow connector to guess keen.timestamp value based on the streamed data."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (163, 'Cassandra-demo', 'airbyte/destination-cassandra', '0.1.3', 'https://docs.airbyte.com/integrations/destinations/cassandra/', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/cassandra.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/cassandra", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Cassandra Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["keyspace", "username", "password", "address", "port"], "properties": {"port": {"type": "integer", "order": 4, "title": "Port", "default": 9042, "maximum": 65536, "minimum": 0, "description": "Port of Cassandra."}, "address": {"type": "string", "order": 3, "title": "Address", "examples": ["localhost,127.0.0.1"], "description": "Address to connect to."}, "keyspace": {"type": "string", "order": 0, "title": "Keyspace", "description": "Default Cassandra keyspace to create data in."}, "password": {"type": "string", "order": 2, "title": "Password", "description": "Password associated with Cassandra.", "airbyte_secret": true}, "username": {"type": "string", "order": 1, "title": "Username", "description": "Username to use to access Cassandra."}, "datacenter": {"type": "string", "order": 5, "title": "Datacenter", "default": "datacenter1", "description": "Datacenter of the cassandra cluster."}, "replication": {"type": "integer", "order": 6, "title": "Replication factor", "default": 1, "description": "Indicates to how many nodes the data should be replicated to."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (164, 'Streamr', 'ghcr.io/devmate-cloud/streamr-airbyte-connectors', '0.0.1', 'https://docs.airbyte.io/integrations/destinations/streamr', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/streamr.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/streamr", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Destination Streamr", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["privateKey", "streamId"], "properties": {"streamId": {"type": "string", "examples": ["0x0d0102474519cd2fc1b3e3f962a87e39cbcbead2/test-streamr"], "description": "Your full Stream ID"}, "privateKey": {"type": "string", "description": "You private key on Streamr", "airbyte_secret": true}}, "additionalProperties": false}, "supported_destination_sync_modes": ["append", "append_dedup"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (166, 'SFTP-JSON', 'airbyte/destination-sftp-json', '0.1.0', 'https://docs.airbyte.io/integrations/destinations/sftp-json', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/sftp.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/sftp-json", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Destination SFTP JSON", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "username", "password", "destination_path"], "properties": {"host": {"type": "string", "order": 0, "title": "Host", "description": "Hostname of the SFTP server."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": [22], "description": "Port of the SFTP server."}, "password": {"type": "string", "order": 3, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 2, "title": "User", "description": "Username to use to access the SFTP server."}, "destination_path": {"type": "string", "order": 4, "title": "Destination path", "examples": ["/json_data"], "description": "Path to the directory where json files will be written."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (167, 'Cassandra', 'airbyte/destination-cassandra', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/cassandra', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/cassandra.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/cassandra", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Cassandra Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["keyspace", "username", "password", "address", "port"], "properties": {"port": {"type": "integer", "order": 4, "title": "Port", "default": 9042, "maximum": 65536, "minimum": 0, "description": "Port of Cassandra."}, "address": {"type": "string", "order": 3, "title": "Address", "examples": ["localhost,127.0.0.1"], "description": "Address to connect to."}, "keyspace": {"type": "string", "order": 0, "title": "Keyspace", "description": "Default Cassandra keyspace to create data in."}, "password": {"type": "string", "order": 2, "title": "Password", "description": "Password associated with Cassandra.", "airbyte_secret": true}, "username": {"type": "string", "order": 1, "title": "Username", "description": "Username to use to access Cassandra."}, "datacenter": {"type": "string", "order": 5, "title": "Datacenter", "default": "datacenter1", "description": "Datacenter of the cassandra cluster."}, "replication": {"type": "integer", "order": 6, "title": "Replication factor", "default": 1, "description": "Indicates to how many nodes the data should be replicated to."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (168, 'AWS Datalake', 'airbyte/destination-aws-datalake', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/aws-datalake', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/aws-datalake", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "AWS Datalake Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["credentials", "region", "bucket_name", "bucket_prefix"], "properties": {"region": {"type": "string", "title": "AWS Region", "description": "Region name", "airbyte_secret": false}, "bucket_name": {"type": "string", "title": "S3 Bucket Name", "description": "Name of the bucket", "airbyte_secret": false}, "credentials": {"type": "object", "oneOf": [{"type": "object", "title": "IAM Role", "required": ["role_arn", "credentials_title"], "properties": {"role_arn": {"type": "string", "title": "Target Role Arn", "description": "Will assume this role to write data to s3", "airbyte_secret": false}, "credentials_title": {"enum": ["IAM Role"], "type": "string", "const": "IAM Role", "order": 0, "title": "Credentials Title", "default": "IAM Role", "description": "Name of the credentials"}}}, {"type": "object", "title": "IAM User", "required": ["credentials_title", "aws_access_key_id", "aws_secret_access_key"], "properties": {"aws_access_key_id": {"type": "string", "title": "Access Key Id", "description": "AWS User Access Key Id", "airbyte_secret": true}, "credentials_title": {"enum": ["IAM User"], "type": "string", "const": "IAM User", "order": 0, "title": "Credentials Title", "default": "IAM User", "description": "Name of the credentials"}, "aws_secret_access_key": {"type": "string", "title": "Secret Access Key", "description": "Secret Access Key", "airbyte_secret": true}}}], "title": "Authentication mode", "description": "Choose How to Authenticate to AWS."}, "bucket_prefix": {"type": "string", "title": "Target S3 Bucket Prefix", "description": "S3 prefix", "airbyte_secret": false}, "aws_account_id": {"type": "string", "title": "AWS Account Id", "examples": ["111111111111"], "description": "target aws account id"}, "lakeformation_database_name": {"type": "string", "title": "Lakeformation Database Name", "description": "Which database to use", "airbyte_secret": false}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (170, 'Azure Blob Storage', 'airbyte/destination-azure-blob-storage', '0.1.4', 'https://docs.airbyte.io/integrations/destinations/azureblobstorage', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/azureblobstorage.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/azureblobstorage", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "AzureBlobStorage Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["azure_blob_storage_account_name", "azure_blob_storage_account_key", "format"], "properties": {"format": {"type": "object", "oneOf": [{"title": "CSV: Comma-Separated Values", "required": ["format_type", "flattening"], "properties": {"flattening": {"enum": ["No flattening", "Root level flattening"], "type": "string", "title": "Normalization (Flattening)", "default": "No flattening", "description": "Whether the input json data should be normalized (flattened) in the output CSV. Please refer to docs for details."}, "format_type": {"type": "string", "const": "CSV"}}}, {"title": "JSON Lines: newline-delimited JSON", "required": ["format_type"], "properties": {"format_type": {"type": "string", "const": "JSONL"}}}], "title": "Output Format", "description": "Output data format"}, "azure_blob_storage_account_key": {"type": "string", "title": "Azure Blob Storage account key", "examples": ["Z8ZkZpteggFx394vm+PJHnGTvdRncaYS+JhLKdj789YNmD+iyGTnG+PV+POiuYNhBg/ACS+LKjd%4FG3FHGN12Nd=="], "description": "The Azure blob storage account key.", "airbyte_secret": true}, "azure_blob_storage_account_name": {"type": "string", "title": "Azure Blob Storage account name", "examples": ["airbyte5storage"], "description": "The account''s name of the Azure Blob Storage."}, "azure_blob_storage_container_name": {"type": "string", "title": "Azure blob storage container (Bucket) Name", "examples": ["airbytetescontainername"], "description": "The name of the Azure blob storage container. If not exists - will be created automatically. May be empty, then will be created automatically airbytecontainer+timestamp"}, "azure_blob_storage_output_buffer_size": {"type": "integer", "title": "Azure Blob Storage output buffer size (Megabytes)", "default": 5, "maximum": 2047, "minimum": 1, "examples": [5], "description": "The amount of megabytes to buffer for the output stream to Azure. This will impact memory footprint on workers, but may need adjustment for performance and appropriate block size in Azure."}, "azure_blob_storage_endpoint_domain_name": {"type": "string", "title": "Endpoint Domain Name", "default": "blob.core.windows.net", "examples": ["blob.core.windows.net"], "description": "This is Azure Blob Storage endpoint domain name. Leave default value (or leave it empty if run container from command line) to use Microsoft native from example."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, '{"jobSpecific": [{"jobType": "sync", "resourceRequirements": {"memory_limit": "1Gi", "memory_request": "1Gi"}}]}', 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (172, 'Redis', 'airbyte/destination-redis', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/redis', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/redis.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/redis", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Redis Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "username", "password", "cache_type"], "properties": {"host": {"type": "string", "order": 1, "title": "Host", "examples": ["localhost,127.0.0.1"], "description": "Redis host to connect to."}, "port": {"type": "integer", "order": 2, "title": "Port", "default": 6379, "maximum": 65536, "minimum": 0, "description": "Port of Redis."}, "password": {"type": "string", "order": 4, "title": "Password", "description": "Password associated with Redis.", "airbyte_secret": true}, "username": {"type": "string", "order": 3, "title": "Username", "description": "Username associated with Redis."}, "cache_type": {"enum": ["hash"], "type": "string", "order": 5, "title": "Cache type", "default": "hash", "description": "Redis cache type to store data in."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (173, 'Scylla', 'airbyte/destination-scylla', '0.1.1', 'https://docs.airbyte.io/integrations/destinations/scylla', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/scylla.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/scylla", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "Scylla Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["keyspace", "username", "password", "address", "port"], "properties": {"port": {"type": "integer", "order": 4, "title": "Port", "default": 9042, "maximum": 65536, "minimum": 0, "description": "Port of Scylla."}, "address": {"type": "string", "order": 3, "title": "Address", "description": "Address to connect to."}, "keyspace": {"type": "string", "order": 0, "title": "Keyspace", "description": "Default Scylla keyspace to create data in."}, "password": {"type": "string", "order": 2, "title": "Password", "description": "Password associated with Scylla.", "airbyte_secret": true}, "username": {"type": "string", "order": 1, "title": "Username", "description": "Username to use to access Scylla."}, "replication": {"type": "integer", "order": 5, "title": "Replication factor", "default": 1, "description": "Indicates to how many nodes the data should be replicated to."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 0, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (175, 'Clickhouse', 'airbyte/destination-clickhouse', '0.1.6', 'https://docs.airbyte.io/integrations/destinations/clickhouse', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/clickhouse", "supportsIncremental": true, "supportsNormalization": true, "connectionSpecification": {"type": "object", "title": "ClickHouse Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["host", "port", "database", "username"], "properties": {"ssl": {"type": "boolean", "order": 6, "title": "SSL Connection", "default": false, "description": "Encrypt data using SSL."}, "host": {"type": "string", "order": 0, "title": "Host", "description": "Hostname of the database."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 8123, "maximum": 65536, "minimum": 0, "examples": ["8123"], "description": "JDBC port (not the native port) of the database."}, "database": {"type": "string", "order": 3, "title": "DB Name", "description": "Name of the database."}, "password": {"type": "string", "order": 5, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "tcp-port": {"type": "integer", "order": 2, "title": "Native Port", "default": 9000, "maximum": 65536, "minimum": 0, "examples": ["9000"], "description": "Native port (not the JDBC) of the database."}, "username": {"type": "string", "order": 4, "title": "User", "description": "Username to use to access the database."}, "tunnel_method": {"type": "object", "oneOf": [{"title": "No Tunnel", "required": ["tunnel_method"], "properties": {"tunnel_method": {"type": "string", "const": "NO_TUNNEL", "order": 0, "description": "No ssh tunnel needed to connect to database"}}}, {"title": "SSH Key Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "ssh_key"], "properties": {"ssh_key": {"type": "string", "order": 4, "title": "SSH Private Key", "multiline": true, "description": "OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )", "airbyte_secret": true}, "tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host."}, "tunnel_method": {"type": "string", "const": "SSH_KEY_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and ssh key"}}}, {"title": "Password Authentication", "required": ["tunnel_method", "tunnel_host", "tunnel_port", "tunnel_user", "tunnel_user_password"], "properties": {"tunnel_host": {"type": "string", "order": 1, "title": "SSH Tunnel Jump Server Host", "description": "Hostname of the jump server host that allows inbound ssh tunnel."}, "tunnel_port": {"type": "integer", "order": 2, "title": "SSH Connection Port", "default": 22, "maximum": 65536, "minimum": 0, "examples": ["22"], "description": "Port on the proxy/jump server that accepts inbound ssh connections."}, "tunnel_user": {"type": "string", "order": 3, "title": "SSH Login Username", "description": "OS-level username for logging into the jump server host"}, "tunnel_method": {"type": "string", "const": "SSH_PASSWORD_AUTH", "order": 0, "description": "Connect through a jump server tunnel host using username and password authentication"}, "tunnel_user_password": {"type": "string", "order": 4, "title": "Password", "description": "OS-level password for logging into the jump server host", "airbyte_secret": true}}}], "title": "SSH Tunnel Method", "description": "Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append", "append_dedup"]}', 'alpha', null, null, 1, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (179, 'DynamoDB', 'airbyte/destination-dynamodb', '0.1.3', 'https://docs.airbyte.io/integrations/destinations/dynamodb', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/dynamodb.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/dynamodb", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "DynamoDB Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["dynamodb_table_name_prefix", "dynamodb_region", "access_key_id", "secret_access_key"], "properties": {"access_key_id": {"type": "string", "title": "DynamoDB Key Id", "examples": ["A012345678910EXAMPLE"], "description": "The access key id to access the DynamoDB. Airbyte requires Read and Write permissions to the DynamoDB.", "airbyte_secret": true}, "dynamodb_region": {"enum": ["", "us-east-1", "us-east-2", "us-west-1", "us-west-2", "af-south-1", "ap-east-1", "ap-south-1", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-north-1", "eu-south-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1", "me-south-1", "us-gov-east-1", "us-gov-west-1"], "type": "string", "title": "DynamoDB Region", "default": "", "description": "The region of the DynamoDB."}, "dynamodb_endpoint": {"type": "string", "title": "Endpoint", "default": "", "examples": ["http://localhost:9000"], "description": "This is your DynamoDB endpoint url.(if you are working with AWS DynamoDB, just leave empty)."}, "secret_access_key": {"type": "string", "title": "DynamoDB Access Key", "examples": ["a012345678910ABCDEFGH/AbCdEfGhEXAMPLEKEY"], "description": "The corresponding secret to the access key id.", "airbyte_secret": true}, "dynamodb_table_name_prefix": {"type": "string", "title": "Table name prefix", "examples": ["airbyte_sync"], "description": "The prefix to use when naming DynamoDB tables."}}, "additionalProperties": false}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (180, 'MongoDB', 'airbyte/destination-mongodb', '0.1.4', 'https://docs.airbyte.io/integrations/destinations/mongodb', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/mongodb.svg', 'destination', null, '{"supportsDBT": false, "documentationUrl": "https://docs.airbyte.io/integrations/destinations/mongodb", "supportsIncremental": true, "supportsNormalization": false, "connectionSpecification": {"type": "object", "title": "MongoDB Destination Spec", "$schema": "http://json-schema.org/draft-07/schema#", "required": ["database", "auth_type"], "properties": {"database": {"type": "string", "order": 2, "title": "DB Name", "description": "Name of the database."}, "auth_type": {"type": "object", "oneOf": [{"type": "object", "title": "None", "required": ["authorization"], "properties": {"authorization": {"type": "string", "const": "none"}}, "description": "None.", "additionalProperties": false}, {"type": "object", "title": "Login/Password", "required": ["authorization", "username", "password"], "properties": {"password": {"type": "string", "order": 2, "title": "Password", "description": "Password associated with the username.", "airbyte_secret": true}, "username": {"type": "string", "order": 1, "title": "User", "description": "Username to use to access the database."}, "authorization": {"type": "string", "const": "login/password"}}, "description": "Login/Password.", "additionalProperties": false}], "title": "Authorization type", "description": "Authorization type."}, "instance_type": {"type": "object", "oneOf": [{"title": "Standalone MongoDb Instance", "required": ["instance", "host", "port"], "properties": {"tls": {"type": "boolean", "order": 2, "title": "TLS Connection", "default": false, "description": "Indicates whether TLS encryption protocol will be used to connect to MongoDB. It is recommended to use TLS connection if possible. For more information see <a href=\\"https://docs.airbyte.io/integrations/sources/mongodb-v2\\">documentation</a>."}, "host": {"type": "string", "order": 0, "title": "Host", "description": "The Host of a Mongo database to be replicated."}, "port": {"type": "integer", "order": 1, "title": "Port", "default": 27017, "maximum": 65536, "minimum": 0, "examples": ["27017"], "description": "The Port of a Mongo database to be replicated."}, "instance": {"enum": ["standalone"], "type": "string", "default": "standalone"}}}, {"title": "Replica Set", "required": ["instance", "server_addresses"], "properties": {"instance": {"enum": ["replica"], "type": "string", "default": "replica"}, "replica_set": {"type": "string", "order": 1, "title": "Replica Set", "description": "A replica set name."}, "server_addresses": {"type": "string", "order": 0, "title": "Server addresses", "examples": ["host1:27017,host2:27017,host3:27017"], "description": "The members of a replica set. Please specify `host`:`port` of each member seperated by comma."}}}, {"title": "MongoDB Atlas", "required": ["instance", "cluster_url"], "properties": {"instance": {"enum": ["atlas"], "type": "string", "default": "atlas"}, "cluster_url": {"type": "string", "order": 0, "title": "Cluster URL", "description": "URL of a cluster to connect to."}}, "additionalProperties": false}], "order": 0, "title": "MongoDb Instance Type", "description": "MongoDb instance to connect to. For MongoDB Atlas and Replica Set TLS connection is used by default."}}, "additionalProperties": true}, "supported_destination_sync_modes": ["overwrite", "append"]}', 'alpha', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (181, 'my-ds-mysql-demo2', 'airbyte/source-mysql', '0.5.11', 'https://docs.airbyte.com/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/test/datasource/c182485a846f439aad10bbe99466a3e2/16pic_8642553_b.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"additionalProperties":false,"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":7,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 0, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (188, 'my-ds-mysql-demo33', 'airbyte/source-mysql', '0.5.12', 'https://docs.airbyte.com/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/test/datasource/3924875bdef242628023ca55195d16dd/萨摩耶.jpeg', 'destination', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"additionalProperties":false,"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":7,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (189, 'my-ds-mysql-demo44', 'airbyte/source-mysql', '0.5.10', 'https://docs.airbyte.com/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/test/datasource/5196e7d5331d44a4869cfc743978990a/199EA167-143A-4756-96CF-F68BA38778D5.jpeg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"additionalProperties":false,"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":7,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (194, 'my-ds-mysql-demo-out1', 'airbyte/source-mysql', '0.5.12', 'https://docs.airbyte.com/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/test/datasource/aa8c4254a6964f78996fc3bdc8263418/199EA167-143A-4756-96CF-F68BA38778D5.jpeg', 'destination', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"additionalProperties":false,"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":7,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (198, 'zf-test-mysql', 'airbyte/source-mysql', '0.5.11', 'https://docs.airbyte.com/integrations/sources/mysql', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"additionalProperties":false,"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":7,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (199, 'mysql_test_zhangfeng111', 'airbyte/source-mysql', '0.6.6', 'https://docs.airbyte.com/integrations/sources/mysql/', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"ssl_mode":{"title":"SSL modes","description":"SSL connection modes. <li><b>preferred</b> - Automatically attempt SSL connection. If the MySQL server does not support SSL, continue with a regular connection.</li><li><b>required</b> - Always connect with SSL. If the MySQL server doesn’t support SSL, the connection will not be established. Certificate Authority (CA) and Hostname are not verified.</li><li><b>verify-ca</b> - Always connect with SSL. Verifies CA, but allows connection even if Hostname does not match.</li><li><b>Verify Identity</b> - Always connect with SSL. Verify both CA and Hostname.</li></ul>Read more <a href=\\"https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-using-ssl.html\\"> in the docs</a>.","type":"object","order":7,"oneOf":[{"title":"preferred","description":"Preferred SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"preferred","enum":["preferred"],"default":"preferred","order":0}}},{"title":"required","description":"Require SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"required","enum":["required"],"default":"required","order":0}}},{"title":"Verify CA","description":"Verify CA SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_ca","enum":["verify_ca"],"default":"verify_ca","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}},{"title":"Verify Identity","description":"Verify-full SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_identity","enum":["verify_identity"],"default":"verify_identity","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}}]},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":8,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (200, 'gateway', 'airbyte/source-mysql', '0.6.6', 'https://docs.airbyte.com/integrations/sources/mysql/', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"ssl_mode":{"title":"SSL modes","description":"SSL connection modes. <li><b>preferred</b> - Automatically attempt SSL connection. If the MySQL server does not support SSL, continue with a regular connection.</li><li><b>required</b> - Always connect with SSL. If the MySQL server doesn’t support SSL, the connection will not be established. Certificate Authority (CA) and Hostname are not verified.</li><li><b>verify-ca</b> - Always connect with SSL. Verifies CA, but allows connection even if Hostname does not match.</li><li><b>Verify Identity</b> - Always connect with SSL. Verify both CA and Hostname.</li></ul>Read more <a href=\\"https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-using-ssl.html\\"> in the docs</a>.","type":"object","order":7,"oneOf":[{"title":"preferred","description":"Preferred SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"preferred","enum":["preferred"],"default":"preferred","order":0}}},{"title":"required","description":"Require SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"required","enum":["required"],"default":"required","order":0}}},{"title":"Verify CA","description":"Verify CA SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_ca","enum":["verify_ca"],"default":"verify_ca","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}},{"title":"Verify Identity","description":"Verify-full SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_identity","enum":["verify_identity"],"default":"verify_identity","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}}]},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":8,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 0, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (201, 'gateway-1', 'airbyte/source-mysql', '0.6.6', 'https://docs.airbyte.com/integrations/sources/mysql/', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/icons/air_default.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"ssl_mode":{"title":"SSL modes","description":"SSL connection modes. <li><b>preferred</b> - Automatically attempt SSL connection. If the MySQL server does not support SSL, continue with a regular connection.</li><li><b>required</b> - Always connect with SSL. If the MySQL server doesn’t support SSL, the connection will not be established. Certificate Authority (CA) and Hostname are not verified.</li><li><b>verify-ca</b> - Always connect with SSL. Verifies CA, but allows connection even if Hostname does not match.</li><li><b>Verify Identity</b> - Always connect with SSL. Verify both CA and Hostname.</li></ul>Read more <a href=\\"https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-using-ssl.html\\"> in the docs</a>.","type":"object","order":7,"oneOf":[{"title":"preferred","description":"Preferred SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"preferred","enum":["preferred"],"default":"preferred","order":0}}},{"title":"required","description":"Require SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"required","enum":["required"],"default":"required","order":0}}},{"title":"Verify CA","description":"Verify CA SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_ca","enum":["verify_ca"],"default":"verify_ca","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}},{"title":"Verify Identity","description":"Verify-full SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_identity","enum":["verify_identity"],"default":"verify_identity","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}}]},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":8,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 0, '', '0', 'admin', 'admin');
INSERT INTO ds_task_${tenantName}.actor_definition(id, name, docker_repository, docker_image_tag, documentation_url, icon, actor_type, source_type, spec, release_stage, release_date, resource_requirements, for_ds_template, is_open, description, delete_status, create_by, update_by) VALUES (202, 'payment-mysql', 'airbyte/source-mysql', '0.6.6', 'https://docs.airbyte.com/integrations/sources/mysql/', 'https://cbs-flink-sg.obs.ap-southeast-3.myhuaweicloud.com/hebe/cloud-test/datasource/821f471ccaeb41d598a4436e129db224/air_default.jpg', 'source', '', '{"documentationUrl":"https://docs.airbyte.io/integrations/sources/mysql","connectionSpecification":{"$schema":"http://json-schema.org/draft-07/schema#","title":"MySql Source Spec","type":"object","required":["host","port","database","username","replication_method"],"properties":{"host":{"description":"The host name of the database.","title":"Host","type":"string","order":0},"port":{"description":"The port to connect to.","title":"Port","type":"integer","minimum":0,"maximum":65536,"default":3306,"examples":["3306"],"order":1},"database":{"description":"The database name.","title":"Database","type":"string","order":2},"username":{"description":"The username which is used to access the database.","title":"Username","type":"string","order":3},"password":{"description":"The password associated with the username.","title":"Password","type":"string","airbyte_secret":true,"order":4},"jdbc_url_params":{"description":"Additional properties to pass to the JDBC URL string when connecting to the database formatted as ''key=value'' pairs separated by the symbol ''&''. (example: key1=value1&key2=value2&key3=value3).","title":"JDBC URL Params","type":"string","order":5},"ssl":{"title":"SSL Connection","description":"Encrypt data using SSL.","type":"boolean","default":true,"order":6},"ssl_mode":{"title":"SSL modes","description":"SSL connection modes. <li><b>preferred</b> - Automatically attempt SSL connection. If the MySQL server does not support SSL, continue with a regular connection.</li><li><b>required</b> - Always connect with SSL. If the MySQL server doesn’t support SSL, the connection will not be established. Certificate Authority (CA) and Hostname are not verified.</li><li><b>verify-ca</b> - Always connect with SSL. Verifies CA, but allows connection even if Hostname does not match.</li><li><b>Verify Identity</b> - Always connect with SSL. Verify both CA and Hostname.</li></ul>Read more <a href=\\"https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-reference-using-ssl.html\\"> in the docs</a>.","type":"object","order":7,"oneOf":[{"title":"preferred","description":"Preferred SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"preferred","enum":["preferred"],"default":"preferred","order":0}}},{"title":"required","description":"Require SSL mode.","required":["mode"],"properties":{"mode":{"type":"string","const":"required","enum":["required"],"default":"required","order":0}}},{"title":"Verify CA","description":"Verify CA SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_ca","enum":["verify_ca"],"default":"verify_ca","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}},{"title":"Verify Identity","description":"Verify-full SSL mode.","required":["mode","ca_certificate"],"properties":{"mode":{"type":"string","const":"verify_identity","enum":["verify_identity"],"default":"verify_identity","order":0},"ca_certificate":{"type":"string","title":"CA certificate","description":"CA certificate","airbyte_secret":true,"multiline":true,"order":1},"client_certificate":{"type":"string","title":"Client certificate","description":"Client certificate (this is not a required field, but if you want to use it, you will need to add the <b>Client key</b> as well)","airbyte_secret":true,"multiline":true,"order":2},"client_key":{"type":"string","title":"Client key","description":"Client key (this is not a required field, but if you want to use it, you will need to add the <b>Client certificate</b> as well)","airbyte_secret":true,"multiline":true,"order":3},"client_key_password":{"type":"string","title":"Client key password (Optional)","description":"Password for keystorage. This field is optional. If you do not add it - the password will be generated automatically.","airbyte_secret":true,"order":4}}}]},"replication_method":{"type":"string","title":"Replication Method","description":"Replication method which is used for data extraction from the database. STANDARD replication requires no setup on the DB side but will not be able to represent deletions incrementally. CDC uses the Binlog to detect inserts, updates, and deletes. This needs to be configured on the source database itself.","order":8,"default":"STANDARD","enum":["STANDARD","CDC"]},"tunnel_method":{"type":"object","title":"SSH Tunnel Method","description":"Whether to initiate an SSH tunnel before connecting to the database, and if so, which kind of authentication to use.","oneOf":[{"title":"No Tunnel","required":["tunnel_method"],"properties":{"tunnel_method":{"description":"No ssh tunnel needed to connect to database","type":"string","const":"NO_TUNNEL","order":0}}},{"title":"SSH Key Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","ssh_key"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and ssh key","type":"string","const":"SSH_KEY_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host.","type":"string","order":3},"ssh_key":{"title":"SSH Private Key","description":"OS-level user account ssh key credentials in RSA PEM format ( created with ssh-keygen -t rsa -m PEM -f myuser_rsa )","type":"string","airbyte_secret":true,"multiline":true,"order":4}}},{"title":"Password Authentication","required":["tunnel_method","tunnel_host","tunnel_port","tunnel_user","tunnel_user_password"],"properties":{"tunnel_method":{"description":"Connect through a jump server tunnel host using username and password authentication","type":"string","const":"SSH_PASSWORD_AUTH","order":0},"tunnel_host":{"title":"SSH Tunnel Jump Server Host","description":"Hostname of the jump server host that allows inbound ssh tunnel.","type":"string","order":1},"tunnel_port":{"title":"SSH Connection Port","description":"Port on the proxy/jump server that accepts inbound ssh connections.","type":"integer","minimum":0,"maximum":65536,"default":22,"examples":["22"],"order":2},"tunnel_user":{"title":"SSH Login Username","description":"OS-level username for logging into the jump server host","type":"string","order":3},"tunnel_user_password":{"title":"Password","description":"OS-level password for logging into the jump server host","type":"string","airbyte_secret":true,"order":4}}}]}}},"supportsNormalization":false,"supportsDBT":false,"supported_destination_sync_modes":[]}', 'custom', null, null, 0, 1, '', '0', 'admin', 'admin');

insert into ds_task_${tenantName}.`spark_log_url`(`id`,`index_pattern`,`index_id`,`region`,`group`,`url`) values
('1','bdp_spark_error_stderr_*','4e8a7cb0-7417-11ea-9058-2f4c73efec4f','ue1','bdp','http://kibana-ue1.ushareit.org/app/kibana#/discover?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-1d,to:now))&_a=(columns:!(log_msg,pod,log_level),filters:!((\'$state\':(store:appState),meta:(alias:!n,disabled:!f,index:\'4e8a7cb0-7417-11ea-9058-2f4c73efec4f\',key:labels.spark-app-selector,negate:!f,params:(query:%s),type:phrase),query:(match_phrase:(labels.spark-app-selector:%s)))),index:\'4e8a7cb0-7417-11ea-9058-2f4c73efec4f\',interval:auto,query:(language:kuery,query:\'\'),sort:!(!(\'@timestamp\',desc)))');

insert into ds_task_${tenantName}.`template_region_imp`(`id`,`template_code`,`region_code`,`url`,`main_class`,`CREATE_BY`,`CREATE_TIME`,`UPDATE_BY`,`UPDATE_TIME`,`description`,`image`) values
('1','Hive2Mysql','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:29:23','',''),
('2','Hive2Mysql','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:28:53','',''),
('3','Hive2Mysql','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:27:17','',''),
('4','Hive2Sharestore','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.rocksdbetl.RocksDbSstBuilder','liangyz','2021-07-16 03:46:09','','2022-12-19 12:27:17','','848318613114.dkr.ecr.us-east-1.amazonaws.com/cbs/sharestore_admin:0.5'),
('5','Hive2Clickhouse','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:29:23','',''),
('6','Hive2Clickhouse','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:28:53','',''),
('7','Hive2Clickhouse','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:27:17','',''),
('8','Hive2Sharestore','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.rocksdbetl.RocksDbSstBuilder','liangyz','2021-07-16 03:46:09','','2022-12-19 12:29:23','','848318613114.dkr.ecr.us-east-1.amazonaws.com/cbs/sharestore_admin:0.5'),
('9','Hive2Sharestore','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.rocksdbetl.RocksDbSstBuilder','liangyz','2021-07-16 03:46:09','','2022-12-19 12:28:53','','swr.ap-southeast-3.myhuaweicloud.com/shareit-cbs/sharestore_admin:0.5'),
('10','Mysql2Hive','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBExporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:29:23','',''),
('11','Mysql2Hive','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBExporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:28:53','',''),
('12','Mysql2Hive','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBExporter','liangyz','2021-07-16 03:46:09','','2022-12-19 12:27:17','',''),
('13','DataMigration','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.migration.SparkSqlMigration','liangyz','2021-07-16 03:46:09','','2022-12-19 12:29:23','','848318613114.dkr.ecr.ap-southeast-1.amazonaws.com/bdp/spark:2.4.3.14-hadoop-2.8.5-amzn-5'),
('14','DataMigration','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.migration.SparkSqlMigration','liangyz','2021-07-16 03:46:09','','2022-12-19 12:28:53','','swr.ap-southeast-3.myhuaweicloud.com/shareit-bdp/spark:2.4.3.14-rc4-hadoop-3.1.1-mrs-10'),
('15','DataMigration','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.migration.SparkSqlMigration','liangyz','2021-07-16 03:46:09','','2022-12-19 12:27:17','','848318613114.dkr.ecr.us-east-1.amazonaws.com/bdp/spark:2.4.3.14-hadoop-2.8.5-amzn-5'),
('16','Hive2Redis','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.redis.importRedis','luhongyu','2022-04-15 06:58:29',null,'2022-12-19 12:27:17',null,null),
('17','Hive2Redis','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.redis.importRedis','luhongyu','2022-04-15 06:58:29',null,'2022-12-19 12:29:23',null,null),
('18','Hive2Redis','SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.redis.importRedis','luhongyu','2022-04-15 06:58:29',null,'2022-12-19 12:28:53',null,null),
('19','Hive2File','SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.sendEmail.sendEmail','luhongyu','2022-09-13 09:49:08',null,'2022-12-19 12:29:23',null,null),
('20','Hive2File','UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.sendEmail.sendEmail','luhongyu','2022-09-13 09:49:14',null,'2022-12-19 12:27:17',null,null),
('21','Hive2File', 'SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-0.9-SNAPSHOT.jar','com.ushareit.data.template.sendEmail.sendEmail','luhongyu','2022-09-13 09:49:24',null,'2022-12-19 12:28:53',null,null),
('22','Hive2Doris', 'SG1','s3://shareit.deploy.ap-southeast-1/BDP/BDP-ds-template/ds-template-1.3-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','luhongyu','2022-09-13 09:49:08',null,'2022-12-19 12:29:23',null,null),
('23','Hive2Doris', 'UE1','s3://shareit.deploy.us-east-1/BDP/BDP-ds-template/ds-template-1.3-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','luhongyu','2022-09-13 09:49:14',null,'2022-12-19 12:27:17',null,null),
('24','Hive2Doris', 'SG2','obs://bdp-deploy-sg/BDP/BDP-ds-template/ds-template-1.3-SNAPSHOT.jar','com.ushareit.data.template.dbetl.DBImporter','luhongyu','2022-09-13 09:49:24',null,'2022-12-19 12:28:53',null,null);

-- 初始化连接器定义表
INSERT INTO ds_task_${tenantName}.dept_info(organization_name,cost_name, parent_id, is_effective_cost, delete_status, create_by, create_time, update_by, update_time) VALUES('default', 'default', NULL, 1, '0', 'xuebotao', '2022-03-10 02:39:43', '', '2022-03-29 03:06:03');